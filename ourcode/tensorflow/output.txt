# Images found: 100000
# Images found: 10000
[2017-11-20 13:44:37]:
-Iter 0, Training Loss= 4.822026, Accuracy Top1 = 0.0000, Top5 = 0.0375
-Iter 0, Validation Loss= 4.811559, Accuracy Top1 = 0.0125, Top5 = 0.0875
[2017-11-20 13:46:04]:
-Iter 100, Training Loss= 5.498018, Accuracy Top1 = 0.1000, Top5 = 0.2625
-Iter 100, Validation Loss= 5.948217, Accuracy Top1 = 0.0750, Top5 = 0.1625
[2017-11-20 13:47:27]:
-Iter 200, Training Loss= 4.118585, Accuracy Top1 = 0.0625, Top5 = 0.1750
-Iter 200, Validation Loss= 4.623296, Accuracy Top1 = 0.0375, Top5 = 0.1500
[2017-11-20 13:48:54]:
-Iter 300, Training Loss= 4.408243, Accuracy Top1 = 0.0250, Top5 = 0.2875
-Iter 300, Validation Loss= 4.693879, Accuracy Top1 = 0.0875, Top5 = 0.2625
[2017-11-20 13:50:22]:
-Iter 400, Training Loss= 3.692764, Accuracy Top1 = 0.1750, Top5 = 0.3750
-Iter 400, Validation Loss= 3.927025, Accuracy Top1 = 0.1750, Top5 = 0.3625
[2017-11-20 13:51:50]:
-Iter 500, Training Loss= 3.564355, Accuracy Top1 = 0.1750, Top5 = 0.4125
-Iter 500, Validation Loss= 3.836415, Accuracy Top1 = 0.1375, Top5 = 0.3500
[2017-11-20 13:53:18]:
-Iter 600, Training Loss= 4.226724, Accuracy Top1 = 0.1500, Top5 = 0.3125
-Iter 600, Validation Loss= 4.384168, Accuracy Top1 = 0.1000, Top5 = 0.3125
[2017-11-20 13:54:46]:
-Iter 700, Training Loss= 4.837110, Accuracy Top1 = 0.0625, Top5 = 0.2125
-Iter 700, Validation Loss= 4.145134, Accuracy Top1 = 0.0750, Top5 = 0.3375
[2017-11-20 13:56:14]:
-Iter 800, Training Loss= 4.591164, Accuracy Top1 = 0.1125, Top5 = 0.3750
-Iter 800, Validation Loss= 4.479605, Accuracy Top1 = 0.1375, Top5 = 0.3000
[2017-11-20 13:57:42]:
-Iter 900, Training Loss= 3.667590, Accuracy Top1 = 0.1625, Top5 = 0.4000
-Iter 900, Validation Loss= 3.329393, Accuracy Top1 = 0.1500, Top5 = 0.4875
[2017-11-20 13:59:11]:
-Iter 1000, Training Loss= 3.188550, Accuracy Top1 = 0.1750, Top5 = 0.4750
-Iter 1000, Validation Loss= 3.585983, Accuracy Top1 = 0.1625, Top5 = 0.4500
[2017-11-20 14:00:40]:
-Iter 1100, Training Loss= 3.383816, Accuracy Top1 = 0.2875, Top5 = 0.5125
-Iter 1100, Validation Loss= 3.848485, Accuracy Top1 = 0.1500, Top5 = 0.4500
[2017-11-20 14:02:09]:
-Iter 1200, Training Loss= 3.483194, Accuracy Top1 = 0.1625, Top5 = 0.4125
-Iter 1200, Validation Loss= 3.273399, Accuracy Top1 = 0.2375, Top5 = 0.5125
[2017-11-20 14:03:34]:
-Iter 1300, Training Loss= 3.163802, Accuracy Top1 = 0.2250, Top5 = 0.5500
-Iter 1300, Validation Loss= 3.688190, Accuracy Top1 = 0.1500, Top5 = 0.5000
[2017-11-20 14:04:56]:
-Iter 1400, Training Loss= 3.880953, Accuracy Top1 = 0.1750, Top5 = 0.3750
-Iter 1400, Validation Loss= 3.900737, Accuracy Top1 = 0.1625, Top5 = 0.3875
[2017-11-20 14:06:17]:
-Iter 1500, Training Loss= 3.226532, Accuracy Top1 = 0.2250, Top5 = 0.5125
-Iter 1500, Validation Loss= 3.191304, Accuracy Top1 = 0.1750, Top5 = 0.5250
[2017-11-20 14:07:39]:
-Iter 1600, Training Loss= 3.037977, Accuracy Top1 = 0.2125, Top5 = 0.5250
-Iter 1600, Validation Loss= 3.487041, Accuracy Top1 = 0.1750, Top5 = 0.4625
[2017-11-20 14:09:00]:
-Iter 1700, Training Loss= 3.353873, Accuracy Top1 = 0.2250, Top5 = 0.4375
-Iter 1700, Validation Loss= 3.764735, Accuracy Top1 = 0.1375, Top5 = 0.3625
[2017-11-20 14:10:22]:
-Iter 1800, Training Loss= 3.282613, Accuracy Top1 = 0.1375, Top5 = 0.4750
-Iter 1800, Validation Loss= 3.500126, Accuracy Top1 = 0.1750, Top5 = 0.4750
[2017-11-20 14:11:43]:
-Iter 1900, Training Loss= 3.175320, Accuracy Top1 = 0.2500, Top5 = 0.5000
-Iter 1900, Validation Loss= 3.350848, Accuracy Top1 = 0.1875, Top5 = 0.4625
[2017-11-20 14:13:05]:
-Iter 2000, Training Loss= 3.197214, Accuracy Top1 = 0.2250, Top5 = 0.5125
-Iter 2000, Validation Loss= 3.025082, Accuracy Top1 = 0.2875, Top5 = 0.5375
[2017-11-20 14:14:26]:
-Iter 2100, Training Loss= 3.411335, Accuracy Top1 = 0.2125, Top5 = 0.4625
-Iter 2100, Validation Loss= 3.234801, Accuracy Top1 = 0.2125, Top5 = 0.4750
[2017-11-20 14:15:47]:
-Iter 2200, Training Loss= 3.040180, Accuracy Top1 = 0.2500, Top5 = 0.4750
-Iter 2200, Validation Loss= 3.076958, Accuracy Top1 = 0.2875, Top5 = 0.5250
[2017-11-20 14:17:09]:
-Iter 2300, Training Loss= 3.365636, Accuracy Top1 = 0.2500, Top5 = 0.4875
-Iter 2300, Validation Loss= 3.128526, Accuracy Top1 = 0.1875, Top5 = 0.5125
[2017-11-20 14:18:30]:
-Iter 2400, Training Loss= 2.861462, Accuracy Top1 = 0.2750, Top5 = 0.5750
-Iter 2400, Validation Loss= 3.802819, Accuracy Top1 = 0.2125, Top5 = 0.4750
[2017-11-20 14:19:51]:
-Iter 2500, Training Loss= 3.083194, Accuracy Top1 = 0.2000, Top5 = 0.5250
-Iter 2500, Validation Loss= 3.070550, Accuracy Top1 = 0.2000, Top5 = 0.4875
[2017-11-20 14:21:13]:
-Iter 2600, Training Loss= 2.543201, Accuracy Top1 = 0.3500, Top5 = 0.6625
-Iter 2600, Validation Loss= 2.808609, Accuracy Top1 = 0.2250, Top5 = 0.5750
[2017-11-20 14:22:34]:
-Iter 2700, Training Loss= 3.152149, Accuracy Top1 = 0.1875, Top5 = 0.4750
-Iter 2700, Validation Loss= 2.936257, Accuracy Top1 = 0.2625, Top5 = 0.5750
[2017-11-20 14:23:55]:
-Iter 2800, Training Loss= 3.262239, Accuracy Top1 = 0.2625, Top5 = 0.4375
-Iter 2800, Validation Loss= 2.870663, Accuracy Top1 = 0.2750, Top5 = 0.5375
[2017-11-20 14:25:16]:
-Iter 2900, Training Loss= 3.160668, Accuracy Top1 = 0.2875, Top5 = 0.4750
-Iter 2900, Validation Loss= 3.622612, Accuracy Top1 = 0.1375, Top5 = 0.5125
[2017-11-20 14:26:38]:
-Iter 3000, Training Loss= 3.025529, Accuracy Top1 = 0.2375, Top5 = 0.5875
-Iter 3000, Validation Loss= 3.104504, Accuracy Top1 = 0.2000, Top5 = 0.5250
[2017-11-20 14:27:59]:
-Iter 3100, Training Loss= 3.156207, Accuracy Top1 = 0.2250, Top5 = 0.4625
-Iter 3100, Validation Loss= 3.259850, Accuracy Top1 = 0.2000, Top5 = 0.4625
[2017-11-20 14:29:21]:
-Iter 3200, Training Loss= 2.758561, Accuracy Top1 = 0.2375, Top5 = 0.6000
-Iter 3200, Validation Loss= 2.542410, Accuracy Top1 = 0.3625, Top5 = 0.6500
[2017-11-20 14:30:42]:
-Iter 3300, Training Loss= 2.647381, Accuracy Top1 = 0.3875, Top5 = 0.6375
-Iter 3300, Validation Loss= 2.591392, Accuracy Top1 = 0.2875, Top5 = 0.5875
[2017-11-20 14:32:03]:
-Iter 3400, Training Loss= 2.877169, Accuracy Top1 = 0.2750, Top5 = 0.5750
-Iter 3400, Validation Loss= 3.251937, Accuracy Top1 = 0.2750, Top5 = 0.6000
[2017-11-20 14:33:24]:
-Iter 3500, Training Loss= 2.729235, Accuracy Top1 = 0.2750, Top5 = 0.6375
-Iter 3500, Validation Loss= 2.913706, Accuracy Top1 = 0.2750, Top5 = 0.6000
[2017-11-20 14:34:46]:
-Iter 3600, Training Loss= 2.758898, Accuracy Top1 = 0.3500, Top5 = 0.5750
-Iter 3600, Validation Loss= 3.030517, Accuracy Top1 = 0.3000, Top5 = 0.6000
[2017-11-20 14:36:07]:
-Iter 3700, Training Loss= 2.752695, Accuracy Top1 = 0.3125, Top5 = 0.6125
-Iter 3700, Validation Loss= 2.688447, Accuracy Top1 = 0.2750, Top5 = 0.6750
[2017-11-20 14:37:29]:
-Iter 3800, Training Loss= 2.566006, Accuracy Top1 = 0.3375, Top5 = 0.6375
-Iter 3800, Validation Loss= 2.648238, Accuracy Top1 = 0.2875, Top5 = 0.5500
[2017-11-20 14:38:52]:
-Iter 3900, Training Loss= 2.686291, Accuracy Top1 = 0.3125, Top5 = 0.6000
-Iter 3900, Validation Loss= 2.873339, Accuracy Top1 = 0.2500, Top5 = 0.5750
[2017-11-20 14:40:14]:
-Iter 4000, Training Loss= 2.788480, Accuracy Top1 = 0.3125, Top5 = 0.6250
-Iter 4000, Validation Loss= 2.933491, Accuracy Top1 = 0.3125, Top5 = 0.6000
[2017-11-20 14:41:35]:
-Iter 4100, Training Loss= 2.315764, Accuracy Top1 = 0.4375, Top5 = 0.7250
-Iter 4100, Validation Loss= 2.672387, Accuracy Top1 = 0.3000, Top5 = 0.5750
[2017-11-20 14:42:58]:
-Iter 4200, Training Loss= 2.599715, Accuracy Top1 = 0.3375, Top5 = 0.6500
-Iter 4200, Validation Loss= 2.816538, Accuracy Top1 = 0.2875, Top5 = 0.6250
[2017-11-20 14:44:20]:
-Iter 4300, Training Loss= 2.622681, Accuracy Top1 = 0.3750, Top5 = 0.6625
-Iter 4300, Validation Loss= 2.808940, Accuracy Top1 = 0.2875, Top5 = 0.6250
[2017-11-20 14:45:41]:
-Iter 4400, Training Loss= 2.480701, Accuracy Top1 = 0.4375, Top5 = 0.6625
-Iter 4400, Validation Loss= 3.170278, Accuracy Top1 = 0.2500, Top5 = 0.5125
[2017-11-20 14:47:03]:
-Iter 4500, Training Loss= 2.845885, Accuracy Top1 = 0.2500, Top5 = 0.5625
-Iter 4500, Validation Loss= 2.945352, Accuracy Top1 = 0.2750, Top5 = 0.5625
[2017-11-20 14:48:24]:
-Iter 4600, Training Loss= 2.880641, Accuracy Top1 = 0.2500, Top5 = 0.5750
-Iter 4600, Validation Loss= 2.822510, Accuracy Top1 = 0.3375, Top5 = 0.6000
[2017-11-20 14:49:46]:
-Iter 4700, Training Loss= 2.753720, Accuracy Top1 = 0.3750, Top5 = 0.6000
-Iter 4700, Validation Loss= 2.850456, Accuracy Top1 = 0.3000, Top5 = 0.5875
[2017-11-20 14:51:07]:
-Iter 4800, Training Loss= 3.024292, Accuracy Top1 = 0.2875, Top5 = 0.5500
-Iter 4800, Validation Loss= 3.067703, Accuracy Top1 = 0.2750, Top5 = 0.5500
[2017-11-20 14:52:28]:
-Iter 4900, Training Loss= 2.359698, Accuracy Top1 = 0.4500, Top5 = 0.7375
-Iter 4900, Validation Loss= 2.486259, Accuracy Top1 = 0.3625, Top5 = 0.6125
[2017-11-20 14:53:49]:
-Iter 5000, Training Loss= 2.647817, Accuracy Top1 = 0.3000, Top5 = 0.6375
-Iter 5000, Validation Loss= 2.979154, Accuracy Top1 = 0.2000, Top5 = 0.5250
[2017-11-20 14:55:11]:
-Iter 5100, Training Loss= 2.273363, Accuracy Top1 = 0.3750, Top5 = 0.7250
-Iter 5100, Validation Loss= 2.700291, Accuracy Top1 = 0.3000, Top5 = 0.6250
[2017-11-20 14:56:32]:
-Iter 5200, Training Loss= 2.845979, Accuracy Top1 = 0.2500, Top5 = 0.6125
-Iter 5200, Validation Loss= 2.656101, Accuracy Top1 = 0.3500, Top5 = 0.6875
[2017-11-20 14:57:53]:
-Iter 5300, Training Loss= 2.884319, Accuracy Top1 = 0.2875, Top5 = 0.6125
-Iter 5300, Validation Loss= 2.884495, Accuracy Top1 = 0.2625, Top5 = 0.5500
[2017-11-20 14:59:14]:
-Iter 5400, Training Loss= 2.197859, Accuracy Top1 = 0.4375, Top5 = 0.7625
-Iter 5400, Validation Loss= 2.400514, Accuracy Top1 = 0.3125, Top5 = 0.7000
[2017-11-20 15:00:36]:
-Iter 5500, Training Loss= 2.811461, Accuracy Top1 = 0.2625, Top5 = 0.5875
-Iter 5500, Validation Loss= 2.910835, Accuracy Top1 = 0.3625, Top5 = 0.6250
[2017-11-20 15:01:57]:
-Iter 5600, Training Loss= 2.761727, Accuracy Top1 = 0.3250, Top5 = 0.5750
-Iter 5600, Validation Loss= 2.802282, Accuracy Top1 = 0.2375, Top5 = 0.6250
[2017-11-20 15:03:19]:
-Iter 5700, Training Loss= 2.372113, Accuracy Top1 = 0.3375, Top5 = 0.6875
-Iter 5700, Validation Loss= 2.504491, Accuracy Top1 = 0.3500, Top5 = 0.6625
[2017-11-20 15:04:40]:
-Iter 5800, Training Loss= 2.319265, Accuracy Top1 = 0.4000, Top5 = 0.6875
-Iter 5800, Validation Loss= 2.786806, Accuracy Top1 = 0.2875, Top5 = 0.5750
[2017-11-20 15:06:02]:
-Iter 5900, Training Loss= 2.453385, Accuracy Top1 = 0.3875, Top5 = 0.6500
-Iter 5900, Validation Loss= 2.986794, Accuracy Top1 = 0.3250, Top5 = 0.6250
[2017-11-20 15:07:24]:
-Iter 6000, Training Loss= 2.419986, Accuracy Top1 = 0.4125, Top5 = 0.6625
-Iter 6000, Validation Loss= 2.723820, Accuracy Top1 = 0.3125, Top5 = 0.5750
[2017-11-20 15:08:46]:
-Iter 6100, Training Loss= 2.241670, Accuracy Top1 = 0.4375, Top5 = 0.6875
-Iter 6100, Validation Loss= 2.405010, Accuracy Top1 = 0.3625, Top5 = 0.6750
[2017-11-20 15:10:08]:
-Iter 6200, Training Loss= 2.460217, Accuracy Top1 = 0.3125, Top5 = 0.7125
-Iter 6200, Validation Loss= 2.692682, Accuracy Top1 = 0.2625, Top5 = 0.6000
[2017-11-20 15:11:30]:
-Iter 6300, Training Loss= 2.235037, Accuracy Top1 = 0.4000, Top5 = 0.7375
-Iter 6300, Validation Loss= 2.629078, Accuracy Top1 = 0.3250, Top5 = 0.6625
[2017-11-20 15:12:52]:
-Iter 6400, Training Loss= 2.087525, Accuracy Top1 = 0.4875, Top5 = 0.7250
-Iter 6400, Validation Loss= 2.532303, Accuracy Top1 = 0.3000, Top5 = 0.6000
[2017-11-20 15:14:14]:
-Iter 6500, Training Loss= 2.386994, Accuracy Top1 = 0.3500, Top5 = 0.6750
-Iter 6500, Validation Loss= 2.289736, Accuracy Top1 = 0.3500, Top5 = 0.7500
[2017-11-20 15:15:36]:
-Iter 6600, Training Loss= 2.080529, Accuracy Top1 = 0.4625, Top5 = 0.7500
-Iter 6600, Validation Loss= 2.362021, Accuracy Top1 = 0.3750, Top5 = 0.6875
[2017-11-20 15:16:58]:
-Iter 6700, Training Loss= 2.108177, Accuracy Top1 = 0.4500, Top5 = 0.7500
-Iter 6700, Validation Loss= 2.477893, Accuracy Top1 = 0.3500, Top5 = 0.6875
[2017-11-20 15:18:20]:
-Iter 6800, Training Loss= 2.397143, Accuracy Top1 = 0.4125, Top5 = 0.6375
-Iter 6800, Validation Loss= 2.611610, Accuracy Top1 = 0.3375, Top5 = 0.6500
[2017-11-20 15:19:42]:
-Iter 6900, Training Loss= 2.267865, Accuracy Top1 = 0.4625, Top5 = 0.7500
-Iter 6900, Validation Loss= 2.708220, Accuracy Top1 = 0.3125, Top5 = 0.6000
[2017-11-20 15:21:04]:
-Iter 7000, Training Loss= 2.233330, Accuracy Top1 = 0.4000, Top5 = 0.7625
-Iter 7000, Validation Loss= 2.522996, Accuracy Top1 = 0.3375, Top5 = 0.7000
[2017-11-20 15:22:26]:
-Iter 7100, Training Loss= 2.499376, Accuracy Top1 = 0.3375, Top5 = 0.6875
-Iter 7100, Validation Loss= 2.300552, Accuracy Top1 = 0.4500, Top5 = 0.6750
[2017-11-20 15:23:48]:
-Iter 7200, Training Loss= 2.248326, Accuracy Top1 = 0.3500, Top5 = 0.7125
-Iter 7200, Validation Loss= 2.441880, Accuracy Top1 = 0.3375, Top5 = 0.6500
[2017-11-20 15:25:10]:
-Iter 7300, Training Loss= 2.800549, Accuracy Top1 = 0.3750, Top5 = 0.6250
-Iter 7300, Validation Loss= 2.732867, Accuracy Top1 = 0.2625, Top5 = 0.6250
[2017-11-20 15:26:33]:
-Iter 7400, Training Loss= 2.157382, Accuracy Top1 = 0.4375, Top5 = 0.7375
-Iter 7400, Validation Loss= 2.426445, Accuracy Top1 = 0.3375, Top5 = 0.7000
Model saved at Iter 7500 !
[2017-11-20 15:27:56]:
-Iter 7500, Training Loss= 2.167268, Accuracy Top1 = 0.4250, Top5 = 0.7625
-Iter 7500, Validation Loss= 2.612234, Accuracy Top1 = 0.2500, Top5 = 0.6625
[2017-11-20 15:29:18]:
-Iter 7600, Training Loss= 1.934836, Accuracy Top1 = 0.4500, Top5 = 0.7875
-Iter 7600, Validation Loss= 2.589501, Accuracy Top1 = 0.3625, Top5 = 0.5875
[2017-11-20 15:30:40]:
-Iter 7700, Training Loss= 2.494904, Accuracy Top1 = 0.3250, Top5 = 0.7000
-Iter 7700, Validation Loss= 2.786506, Accuracy Top1 = 0.3750, Top5 = 0.5750
[2017-11-20 15:32:02]:
-Iter 7800, Training Loss= 2.552171, Accuracy Top1 = 0.3500, Top5 = 0.6250
-Iter 7800, Validation Loss= 2.560088, Accuracy Top1 = 0.3250, Top5 = 0.6750
[2017-11-20 15:33:24]:
-Iter 7900, Training Loss= 2.062972, Accuracy Top1 = 0.5250, Top5 = 0.7250
-Iter 7900, Validation Loss= 2.476349, Accuracy Top1 = 0.3250, Top5 = 0.7000
[2017-11-20 15:34:46]:
-Iter 8000, Training Loss= 2.497414, Accuracy Top1 = 0.3000, Top5 = 0.6500
-Iter 8000, Validation Loss= 2.526267, Accuracy Top1 = 0.3250, Top5 = 0.6750
[2017-11-20 15:36:08]:
-Iter 8100, Training Loss= 2.312898, Accuracy Top1 = 0.3750, Top5 = 0.6875
-Iter 8100, Validation Loss= 2.470621, Accuracy Top1 = 0.3625, Top5 = 0.6375
[2017-11-20 15:37:29]:
-Iter 8200, Training Loss= 2.143256, Accuracy Top1 = 0.4500, Top5 = 0.7375
-Iter 8200, Validation Loss= 2.423553, Accuracy Top1 = 0.4250, Top5 = 0.7125
[2017-11-20 15:38:51]:
-Iter 8300, Training Loss= 1.975952, Accuracy Top1 = 0.4750, Top5 = 0.7375
-Iter 8300, Validation Loss= 2.612715, Accuracy Top1 = 0.3375, Top5 = 0.7125
[2017-11-20 15:40:12]:
-Iter 8400, Training Loss= 2.254297, Accuracy Top1 = 0.4000, Top5 = 0.7375
-Iter 8400, Validation Loss= 2.763965, Accuracy Top1 = 0.2750, Top5 = 0.6250
[2017-11-20 15:41:33]:
-Iter 8500, Training Loss= 1.856762, Accuracy Top1 = 0.5000, Top5 = 0.7625
-Iter 8500, Validation Loss= 2.398062, Accuracy Top1 = 0.3000, Top5 = 0.7250
[2017-11-20 15:42:54]:
-Iter 8600, Training Loss= 1.937959, Accuracy Top1 = 0.5000, Top5 = 0.7625
-Iter 8600, Validation Loss= 2.442662, Accuracy Top1 = 0.3750, Top5 = 0.7375
[2017-11-20 15:44:15]:
-Iter 8700, Training Loss= 2.167554, Accuracy Top1 = 0.4000, Top5 = 0.7625
-Iter 8700, Validation Loss= 2.600913, Accuracy Top1 = 0.3000, Top5 = 0.5875
[2017-11-20 15:45:37]:
-Iter 8800, Training Loss= 1.960989, Accuracy Top1 = 0.4875, Top5 = 0.7750
-Iter 8800, Validation Loss= 2.366509, Accuracy Top1 = 0.3500, Top5 = 0.6500
[2017-11-20 15:46:58]:
-Iter 8900, Training Loss= 2.029664, Accuracy Top1 = 0.4875, Top5 = 0.8250
-Iter 8900, Validation Loss= 2.528009, Accuracy Top1 = 0.3375, Top5 = 0.6625
[2017-11-20 15:48:19]:
-Iter 9000, Training Loss= 2.059160, Accuracy Top1 = 0.4125, Top5 = 0.7125
-Iter 9000, Validation Loss= 2.401305, Accuracy Top1 = 0.3875, Top5 = 0.6875
[2017-11-20 15:49:41]:
-Iter 9100, Training Loss= 1.556251, Accuracy Top1 = 0.5625, Top5 = 0.8125
-Iter 9100, Validation Loss= 2.019780, Accuracy Top1 = 0.5000, Top5 = 0.6875
[2017-11-20 15:51:02]:
-Iter 9200, Training Loss= 1.941736, Accuracy Top1 = 0.4375, Top5 = 0.7875
-Iter 9200, Validation Loss= 2.570481, Accuracy Top1 = 0.2875, Top5 = 0.6750
[2017-11-20 15:52:23]:
-Iter 9300, Training Loss= 1.965784, Accuracy Top1 = 0.4250, Top5 = 0.7625
-Iter 9300, Validation Loss= 2.514582, Accuracy Top1 = 0.3875, Top5 = 0.6875
[2017-11-20 15:53:45]:
-Iter 9400, Training Loss= 1.967963, Accuracy Top1 = 0.5375, Top5 = 0.7500
-Iter 9400, Validation Loss= 2.485380, Accuracy Top1 = 0.4125, Top5 = 0.7000
[2017-11-20 15:55:06]:
-Iter 9500, Training Loss= 1.891425, Accuracy Top1 = 0.4000, Top5 = 0.7875
-Iter 9500, Validation Loss= 2.463092, Accuracy Top1 = 0.3125, Top5 = 0.6875
[2017-11-20 15:56:27]:
-Iter 9600, Training Loss= 2.136166, Accuracy Top1 = 0.4625, Top5 = 0.7375
-Iter 9600, Validation Loss= 2.686369, Accuracy Top1 = 0.3250, Top5 = 0.6500
[2017-11-20 15:57:49]:
-Iter 9700, Training Loss= 2.038961, Accuracy Top1 = 0.4750, Top5 = 0.7500
-Iter 9700, Validation Loss= 2.998182, Accuracy Top1 = 0.2750, Top5 = 0.5750
[2017-11-20 15:59:10]:
-Iter 9800, Training Loss= 2.238438, Accuracy Top1 = 0.4125, Top5 = 0.6875
-Iter 9800, Validation Loss= 2.771665, Accuracy Top1 = 0.3875, Top5 = 0.6875
[2017-11-20 16:00:31]:
-Iter 9900, Training Loss= 1.933687, Accuracy Top1 = 0.5125, Top5 = 0.8375
-Iter 9900, Validation Loss= 2.654500, Accuracy Top1 = 0.2875, Top5 = 0.6750
[2017-11-20 16:01:52]:
-Iter 10000, Training Loss= 1.998702, Accuracy Top1 = 0.4375, Top5 = 0.8250
-Iter 10000, Validation Loss= 3.018087, Accuracy Top1 = 0.3250, Top5 = 0.5875
[2017-11-20 16:03:14]:
-Iter 10100, Training Loss= 1.717205, Accuracy Top1 = 0.5875, Top5 = 0.8000
-Iter 10100, Validation Loss= 2.374485, Accuracy Top1 = 0.4750, Top5 = 0.7125
[2017-11-20 16:04:35]:
-Iter 10200, Training Loss= 1.852818, Accuracy Top1 = 0.5000, Top5 = 0.7875
-Iter 10200, Validation Loss= 2.374450, Accuracy Top1 = 0.3875, Top5 = 0.6625
[2017-11-20 16:05:56]:
-Iter 10300, Training Loss= 2.055135, Accuracy Top1 = 0.4375, Top5 = 0.7250
-Iter 10300, Validation Loss= 2.518366, Accuracy Top1 = 0.3625, Top5 = 0.6625
[2017-11-20 16:07:18]:
-Iter 10400, Training Loss= 1.759757, Accuracy Top1 = 0.5750, Top5 = 0.8125
-Iter 10400, Validation Loss= 2.089520, Accuracy Top1 = 0.4125, Top5 = 0.7500
[2017-11-20 16:08:39]:
-Iter 10500, Training Loss= 2.067772, Accuracy Top1 = 0.4125, Top5 = 0.7375
-Iter 10500, Validation Loss= 2.345870, Accuracy Top1 = 0.4000, Top5 = 0.7250
[2017-11-20 16:10:00]:
-Iter 10600, Training Loss= 1.966618, Accuracy Top1 = 0.4375, Top5 = 0.7500
-Iter 10600, Validation Loss= 2.678047, Accuracy Top1 = 0.3500, Top5 = 0.6375
[2017-11-20 16:11:22]:
-Iter 10700, Training Loss= 1.810571, Accuracy Top1 = 0.4625, Top5 = 0.8500
-Iter 10700, Validation Loss= 3.202808, Accuracy Top1 = 0.3250, Top5 = 0.6375
[2017-11-20 16:12:43]:
-Iter 10800, Training Loss= 1.817367, Accuracy Top1 = 0.5250, Top5 = 0.7875
-Iter 10800, Validation Loss= 2.220384, Accuracy Top1 = 0.3875, Top5 = 0.7000
[2017-11-20 16:14:04]:
-Iter 10900, Training Loss= 1.885144, Accuracy Top1 = 0.4625, Top5 = 0.7875
-Iter 10900, Validation Loss= 2.860604, Accuracy Top1 = 0.3625, Top5 = 0.6500
[2017-11-20 16:15:25]:
-Iter 11000, Training Loss= 1.545578, Accuracy Top1 = 0.5500, Top5 = 0.8375
-Iter 11000, Validation Loss= 2.132021, Accuracy Top1 = 0.4125, Top5 = 0.7375
[2017-11-20 16:16:47]:
-Iter 11100, Training Loss= 1.734378, Accuracy Top1 = 0.5125, Top5 = 0.8375
-Iter 11100, Validation Loss= 2.359880, Accuracy Top1 = 0.3625, Top5 = 0.7375
[2017-11-20 16:18:09]:
-Iter 11200, Training Loss= 1.801569, Accuracy Top1 = 0.5625, Top5 = 0.8375
-Iter 11200, Validation Loss= 2.215967, Accuracy Top1 = 0.4500, Top5 = 0.7000
[2017-11-20 16:19:31]:
-Iter 11300, Training Loss= 1.735139, Accuracy Top1 = 0.5750, Top5 = 0.8500
-Iter 11300, Validation Loss= 2.439853, Accuracy Top1 = 0.3500, Top5 = 0.7500
[2017-11-20 16:20:53]:
-Iter 11400, Training Loss= 1.543730, Accuracy Top1 = 0.5625, Top5 = 0.8375
-Iter 11400, Validation Loss= 2.718421, Accuracy Top1 = 0.3250, Top5 = 0.6000
[2017-11-20 16:22:15]:
-Iter 11500, Training Loss= 1.618444, Accuracy Top1 = 0.5375, Top5 = 0.8125
-Iter 11500, Validation Loss= 2.430395, Accuracy Top1 = 0.4750, Top5 = 0.7250
[2017-11-20 16:23:37]:
-Iter 11600, Training Loss= 1.612735, Accuracy Top1 = 0.5500, Top5 = 0.8375
-Iter 11600, Validation Loss= 2.452882, Accuracy Top1 = 0.4125, Top5 = 0.6875
[2017-11-20 16:24:59]:
-Iter 11700, Training Loss= 1.518753, Accuracy Top1 = 0.5750, Top5 = 0.8125
-Iter 11700, Validation Loss= 3.149154, Accuracy Top1 = 0.3250, Top5 = 0.5375
[2017-11-20 16:26:21]:
-Iter 11800, Training Loss= 1.525750, Accuracy Top1 = 0.5875, Top5 = 0.8375
-Iter 11800, Validation Loss= 2.812439, Accuracy Top1 = 0.3500, Top5 = 0.5625
[2017-11-20 16:27:43]:
-Iter 11900, Training Loss= 1.577955, Accuracy Top1 = 0.6000, Top5 = 0.8375
-Iter 11900, Validation Loss= 2.410477, Accuracy Top1 = 0.4125, Top5 = 0.7750
[2017-11-20 16:29:05]:
-Iter 12000, Training Loss= 1.507778, Accuracy Top1 = 0.5750, Top5 = 0.8500
-Iter 12000, Validation Loss= 2.377010, Accuracy Top1 = 0.4875, Top5 = 0.7625
[2017-11-20 16:30:27]:
-Iter 12100, Training Loss= 1.704127, Accuracy Top1 = 0.5000, Top5 = 0.8500
-Iter 12100, Validation Loss= 2.686698, Accuracy Top1 = 0.3375, Top5 = 0.7000
[2017-11-20 16:31:49]:
-Iter 12200, Training Loss= 1.623353, Accuracy Top1 = 0.5500, Top5 = 0.8875
-Iter 12200, Validation Loss= 2.645759, Accuracy Top1 = 0.3750, Top5 = 0.7125
[2017-11-20 16:33:11]:
-Iter 12300, Training Loss= 1.664678, Accuracy Top1 = 0.4875, Top5 = 0.8125
-Iter 12300, Validation Loss= 2.186067, Accuracy Top1 = 0.5000, Top5 = 0.7500
[2017-11-20 16:34:33]:
-Iter 12400, Training Loss= 1.489923, Accuracy Top1 = 0.6125, Top5 = 0.8500
-Iter 12400, Validation Loss= 2.554033, Accuracy Top1 = 0.3500, Top5 = 0.6500
[2017-11-20 16:35:55]:
-Iter 12500, Training Loss= 1.584775, Accuracy Top1 = 0.5250, Top5 = 0.8625
-Iter 12500, Validation Loss= 2.600486, Accuracy Top1 = 0.3125, Top5 = 0.6875
[2017-11-20 16:37:16]:
-Iter 12600, Training Loss= 1.461822, Accuracy Top1 = 0.5750, Top5 = 0.8250
-Iter 12600, Validation Loss= 2.634122, Accuracy Top1 = 0.3875, Top5 = 0.6500
[2017-11-20 16:38:37]:
-Iter 12700, Training Loss= 1.768822, Accuracy Top1 = 0.5250, Top5 = 0.7875
-Iter 12700, Validation Loss= 2.762219, Accuracy Top1 = 0.3625, Top5 = 0.6625
[2017-11-20 16:39:58]:
-Iter 12800, Training Loss= 1.509955, Accuracy Top1 = 0.5750, Top5 = 0.8500
-Iter 12800, Validation Loss= 2.652946, Accuracy Top1 = 0.4000, Top5 = 0.6625
[2017-11-20 16:41:20]:
-Iter 12900, Training Loss= 1.540117, Accuracy Top1 = 0.6125, Top5 = 0.9125
-Iter 12900, Validation Loss= 2.322516, Accuracy Top1 = 0.4250, Top5 = 0.7000
[2017-11-20 16:42:41]:
-Iter 13000, Training Loss= 1.419250, Accuracy Top1 = 0.5875, Top5 = 0.8625
-Iter 13000, Validation Loss= 2.896917, Accuracy Top1 = 0.3875, Top5 = 0.6250
[2017-11-20 16:44:02]:
-Iter 13100, Training Loss= 1.558713, Accuracy Top1 = 0.5875, Top5 = 0.8250
-Iter 13100, Validation Loss= 2.927022, Accuracy Top1 = 0.3750, Top5 = 0.6625
[2017-11-20 16:45:23]:
-Iter 13200, Training Loss= 1.530697, Accuracy Top1 = 0.5750, Top5 = 0.9125
-Iter 13200, Validation Loss= 2.731062, Accuracy Top1 = 0.3375, Top5 = 0.6500
[2017-11-20 16:46:44]:
-Iter 13300, Training Loss= 1.493200, Accuracy Top1 = 0.6500, Top5 = 0.8625
-Iter 13300, Validation Loss= 3.098036, Accuracy Top1 = 0.3375, Top5 = 0.5375
[2017-11-20 16:48:06]:
-Iter 13400, Training Loss= 1.454648, Accuracy Top1 = 0.5500, Top5 = 0.8500
-Iter 13400, Validation Loss= 2.274902, Accuracy Top1 = 0.4000, Top5 = 0.7125
[2017-11-20 16:49:27]:
-Iter 13500, Training Loss= 1.546530, Accuracy Top1 = 0.6250, Top5 = 0.8625
-Iter 13500, Validation Loss= 2.670571, Accuracy Top1 = 0.3750, Top5 = 0.7125
[2017-11-20 16:50:48]:
-Iter 13600, Training Loss= 1.226807, Accuracy Top1 = 0.7125, Top5 = 0.8750
-Iter 13600, Validation Loss= 2.861877, Accuracy Top1 = 0.3375, Top5 = 0.5875
[2017-11-20 16:52:09]:
-Iter 13700, Training Loss= 1.408342, Accuracy Top1 = 0.6125, Top5 = 0.9000
-Iter 13700, Validation Loss= 2.462002, Accuracy Top1 = 0.4375, Top5 = 0.7000
[2017-11-20 16:53:30]:
-Iter 13800, Training Loss= 1.478207, Accuracy Top1 = 0.6375, Top5 = 0.8625
-Iter 13800, Validation Loss= 2.483754, Accuracy Top1 = 0.3875, Top5 = 0.7125
[2017-11-20 16:54:52]:
-Iter 13900, Training Loss= 1.290092, Accuracy Top1 = 0.6375, Top5 = 0.9125
-Iter 13900, Validation Loss= 2.850449, Accuracy Top1 = 0.3375, Top5 = 0.5875
[2017-11-20 16:56:13]:
-Iter 14000, Training Loss= 1.453991, Accuracy Top1 = 0.5375, Top5 = 0.8750
-Iter 14000, Validation Loss= 2.452899, Accuracy Top1 = 0.3125, Top5 = 0.6750
[2017-11-20 16:57:35]:
-Iter 14100, Training Loss= 1.213289, Accuracy Top1 = 0.6500, Top5 = 0.9000
-Iter 14100, Validation Loss= 3.071951, Accuracy Top1 = 0.3750, Top5 = 0.6625
[2017-11-20 16:58:57]:
-Iter 14200, Training Loss= 1.470795, Accuracy Top1 = 0.6000, Top5 = 0.8250
-Iter 14200, Validation Loss= 3.303231, Accuracy Top1 = 0.2875, Top5 = 0.6000
[2017-11-20 17:00:19]:
-Iter 14300, Training Loss= 1.265991, Accuracy Top1 = 0.6375, Top5 = 0.8750
-Iter 14300, Validation Loss= 3.089152, Accuracy Top1 = 0.2375, Top5 = 0.6625
[2017-11-20 17:01:41]:
-Iter 14400, Training Loss= 1.447205, Accuracy Top1 = 0.5875, Top5 = 0.8375
-Iter 14400, Validation Loss= 3.175734, Accuracy Top1 = 0.2750, Top5 = 0.6250
[2017-11-20 17:03:03]:
-Iter 14500, Training Loss= 1.294457, Accuracy Top1 = 0.6125, Top5 = 0.8875
-Iter 14500, Validation Loss= 2.562108, Accuracy Top1 = 0.4125, Top5 = 0.6625
[2017-11-20 17:04:25]:
-Iter 14600, Training Loss= 1.169110, Accuracy Top1 = 0.5875, Top5 = 0.9500
-Iter 14600, Validation Loss= 2.345676, Accuracy Top1 = 0.4250, Top5 = 0.7125
[2017-11-20 17:05:47]:
-Iter 14700, Training Loss= 1.152713, Accuracy Top1 = 0.6500, Top5 = 0.9375
-Iter 14700, Validation Loss= 2.679672, Accuracy Top1 = 0.3375, Top5 = 0.6625
[2017-11-20 17:07:08]:
-Iter 14800, Training Loss= 1.303542, Accuracy Top1 = 0.5875, Top5 = 0.8625
-Iter 14800, Validation Loss= 3.094028, Accuracy Top1 = 0.3500, Top5 = 0.6125
[2017-11-20 17:08:30]:
-Iter 14900, Training Loss= 1.416519, Accuracy Top1 = 0.5500, Top5 = 0.8625
-Iter 14900, Validation Loss= 3.802684, Accuracy Top1 = 0.3000, Top5 = 0.5625
Model saved at Iter 15000 !
[2017-11-20 17:09:53]:
-Iter 15000, Training Loss= 1.246708, Accuracy Top1 = 0.6625, Top5 = 0.9375
-Iter 15000, Validation Loss= 3.006869, Accuracy Top1 = 0.3750, Top5 = 0.6625
[2017-11-20 17:11:15]:
-Iter 15100, Training Loss= 0.980818, Accuracy Top1 = 0.7250, Top5 = 0.9000
-Iter 15100, Validation Loss= 2.918478, Accuracy Top1 = 0.3250, Top5 = 0.6250
[2017-11-20 17:12:37]:
-Iter 15200, Training Loss= 1.046117, Accuracy Top1 = 0.7250, Top5 = 0.9500
-Iter 15200, Validation Loss= 2.518180, Accuracy Top1 = 0.3125, Top5 = 0.6500
[2017-11-20 17:13:59]:
-Iter 15300, Training Loss= 1.096486, Accuracy Top1 = 0.6875, Top5 = 0.9125
-Iter 15300, Validation Loss= 2.964589, Accuracy Top1 = 0.4125, Top5 = 0.6500
[2017-11-20 17:15:21]:
-Iter 15400, Training Loss= 1.182114, Accuracy Top1 = 0.7125, Top5 = 0.9125
-Iter 15400, Validation Loss= 2.772989, Accuracy Top1 = 0.3625, Top5 = 0.6750
[2017-11-20 17:16:42]:
-Iter 15500, Training Loss= 1.055281, Accuracy Top1 = 0.7125, Top5 = 0.9500
-Iter 15500, Validation Loss= 3.271989, Accuracy Top1 = 0.3500, Top5 = 0.6000
[2017-11-20 17:18:03]:
-Iter 15600, Training Loss= 1.168073, Accuracy Top1 = 0.6125, Top5 = 0.8750
-Iter 15600, Validation Loss= 3.078072, Accuracy Top1 = 0.3000, Top5 = 0.5875
[2017-11-20 17:19:25]:
-Iter 15700, Training Loss= 0.975124, Accuracy Top1 = 0.7750, Top5 = 0.9375
-Iter 15700, Validation Loss= 2.291458, Accuracy Top1 = 0.4750, Top5 = 0.7250
[2017-11-20 17:20:46]:
-Iter 15800, Training Loss= 1.237179, Accuracy Top1 = 0.6625, Top5 = 0.9125
-Iter 15800, Validation Loss= 2.801166, Accuracy Top1 = 0.3125, Top5 = 0.6625
[2017-11-20 17:22:07]:
-Iter 15900, Training Loss= 1.222230, Accuracy Top1 = 0.6500, Top5 = 0.9000
-Iter 15900, Validation Loss= 3.108044, Accuracy Top1 = 0.3375, Top5 = 0.7000
[2017-11-20 17:23:29]:
-Iter 16000, Training Loss= 1.196483, Accuracy Top1 = 0.6625, Top5 = 0.9000
-Iter 16000, Validation Loss= 2.878173, Accuracy Top1 = 0.3250, Top5 = 0.6250
[2017-11-20 17:24:50]:
-Iter 16100, Training Loss= 0.986128, Accuracy Top1 = 0.7125, Top5 = 0.9250
-Iter 16100, Validation Loss= 3.069405, Accuracy Top1 = 0.4000, Top5 = 0.6250
[2017-11-20 17:26:11]:
-Iter 16200, Training Loss= 1.056950, Accuracy Top1 = 0.6500, Top5 = 0.9500
-Iter 16200, Validation Loss= 2.293406, Accuracy Top1 = 0.4375, Top5 = 0.7500
[2017-11-20 17:27:33]:
-Iter 16300, Training Loss= 1.347817, Accuracy Top1 = 0.6125, Top5 = 0.8500
-Iter 16300, Validation Loss= 2.538909, Accuracy Top1 = 0.3750, Top5 = 0.7250
[2017-11-20 17:28:55]:
-Iter 16400, Training Loss= 0.854196, Accuracy Top1 = 0.7375, Top5 = 0.9625
-Iter 16400, Validation Loss= 3.199016, Accuracy Top1 = 0.2750, Top5 = 0.6375
[2017-11-20 17:30:17]:
-Iter 16500, Training Loss= 1.246281, Accuracy Top1 = 0.6875, Top5 = 0.8750
-Iter 16500, Validation Loss= 2.913762, Accuracy Top1 = 0.3250, Top5 = 0.6250
[2017-11-20 17:31:39]:
-Iter 16600, Training Loss= 0.854641, Accuracy Top1 = 0.7250, Top5 = 0.9750
-Iter 16600, Validation Loss= 2.638133, Accuracy Top1 = 0.4000, Top5 = 0.7500
[2017-11-20 17:33:01]:
-Iter 16700, Training Loss= 0.953658, Accuracy Top1 = 0.6750, Top5 = 0.9250
-Iter 16700, Validation Loss= 3.071384, Accuracy Top1 = 0.3375, Top5 = 0.6250
[2017-11-20 17:34:23]:
-Iter 16800, Training Loss= 1.185164, Accuracy Top1 = 0.6500, Top5 = 0.9000
-Iter 16800, Validation Loss= 2.848265, Accuracy Top1 = 0.3875, Top5 = 0.6750
[2017-11-20 17:35:45]:
-Iter 16900, Training Loss= 0.927727, Accuracy Top1 = 0.7250, Top5 = 0.9125
-Iter 16900, Validation Loss= 3.700728, Accuracy Top1 = 0.3000, Top5 = 0.5750
[2017-11-20 17:37:07]:
-Iter 17000, Training Loss= 0.919473, Accuracy Top1 = 0.7125, Top5 = 0.9500
-Iter 17000, Validation Loss= 3.144855, Accuracy Top1 = 0.3625, Top5 = 0.5500
[2017-11-20 17:38:29]:
-Iter 17100, Training Loss= 0.965514, Accuracy Top1 = 0.7250, Top5 = 0.9625
-Iter 17100, Validation Loss= 2.620802, Accuracy Top1 = 0.4375, Top5 = 0.7250
[2017-11-20 17:39:51]:
-Iter 17200, Training Loss= 0.870875, Accuracy Top1 = 0.7125, Top5 = 0.9375
-Iter 17200, Validation Loss= 2.646618, Accuracy Top1 = 0.4125, Top5 = 0.6625
[2017-11-20 17:41:13]:
-Iter 17300, Training Loss= 1.070344, Accuracy Top1 = 0.6750, Top5 = 0.9250
-Iter 17300, Validation Loss= 2.873939, Accuracy Top1 = 0.3625, Top5 = 0.6125
[2017-11-20 17:42:35]:
-Iter 17400, Training Loss= 0.996953, Accuracy Top1 = 0.7375, Top5 = 0.9125
-Iter 17400, Validation Loss= 2.695269, Accuracy Top1 = 0.3625, Top5 = 0.6625
[2017-11-20 17:43:57]:
-Iter 17500, Training Loss= 1.091190, Accuracy Top1 = 0.7125, Top5 = 0.9375
-Iter 17500, Validation Loss= 3.476297, Accuracy Top1 = 0.3000, Top5 = 0.6000
[2017-11-20 17:45:19]:
-Iter 17600, Training Loss= 1.034294, Accuracy Top1 = 0.6875, Top5 = 0.9750
-Iter 17600, Validation Loss= 2.680433, Accuracy Top1 = 0.3625, Top5 = 0.6500
[2017-11-20 17:46:41]:
-Iter 17700, Training Loss= 0.980227, Accuracy Top1 = 0.6875, Top5 = 0.9375
-Iter 17700, Validation Loss= 3.056318, Accuracy Top1 = 0.3750, Top5 = 0.6500
[2017-11-20 17:48:03]:
-Iter 17800, Training Loss= 0.896235, Accuracy Top1 = 0.8000, Top5 = 0.9500
-Iter 17800, Validation Loss= 3.153338, Accuracy Top1 = 0.3500, Top5 = 0.6250
[2017-11-20 17:49:25]:
-Iter 17900, Training Loss= 0.660432, Accuracy Top1 = 0.8375, Top5 = 0.9750
-Iter 17900, Validation Loss= 2.430970, Accuracy Top1 = 0.4125, Top5 = 0.7750
[2017-11-20 17:50:47]:
-Iter 18000, Training Loss= 0.996395, Accuracy Top1 = 0.7250, Top5 = 0.9375
-Iter 18000, Validation Loss= 2.727044, Accuracy Top1 = 0.3500, Top5 = 0.6500
[2017-11-20 17:52:09]:
-Iter 18100, Training Loss= 1.169380, Accuracy Top1 = 0.6250, Top5 = 0.9000
-Iter 18100, Validation Loss= 3.423796, Accuracy Top1 = 0.2875, Top5 = 0.6500
[2017-11-20 17:53:31]:
-Iter 18200, Training Loss= 0.633048, Accuracy Top1 = 0.8500, Top5 = 1.0000
-Iter 18200, Validation Loss= 2.841752, Accuracy Top1 = 0.3375, Top5 = 0.6375
[2017-11-20 17:54:53]:
-Iter 18300, Training Loss= 0.962210, Accuracy Top1 = 0.7125, Top5 = 0.9500
-Iter 18300, Validation Loss= 3.304306, Accuracy Top1 = 0.3625, Top5 = 0.6500
[2017-11-20 17:56:15]:
-Iter 18400, Training Loss= 1.003970, Accuracy Top1 = 0.7125, Top5 = 0.9750
-Iter 18400, Validation Loss= 3.093563, Accuracy Top1 = 0.3750, Top5 = 0.7000
[2017-11-20 17:57:37]:
-Iter 18500, Training Loss= 1.010315, Accuracy Top1 = 0.7250, Top5 = 0.9250
-Iter 18500, Validation Loss= 3.456952, Accuracy Top1 = 0.3000, Top5 = 0.6000
[2017-11-20 17:58:59]:
-Iter 18600, Training Loss= 0.678594, Accuracy Top1 = 0.7750, Top5 = 0.9625
-Iter 18600, Validation Loss= 2.483147, Accuracy Top1 = 0.4500, Top5 = 0.7125
[2017-11-20 18:00:21]:
-Iter 18700, Training Loss= 0.865075, Accuracy Top1 = 0.7250, Top5 = 0.9500
-Iter 18700, Validation Loss= 3.544199, Accuracy Top1 = 0.3250, Top5 = 0.6000
[2017-11-20 18:01:43]:
-Iter 18800, Training Loss= 0.766342, Accuracy Top1 = 0.7625, Top5 = 0.9375
-Iter 18800, Validation Loss= 2.951834, Accuracy Top1 = 0.3750, Top5 = 0.7000
[2017-11-20 18:03:05]:
-Iter 18900, Training Loss= 0.769667, Accuracy Top1 = 0.7250, Top5 = 1.0000
-Iter 18900, Validation Loss= 2.746860, Accuracy Top1 = 0.4000, Top5 = 0.7000
[2017-11-20 18:04:27]:
-Iter 19000, Training Loss= 1.095958, Accuracy Top1 = 0.7125, Top5 = 0.9250
-Iter 19000, Validation Loss= 2.931760, Accuracy Top1 = 0.3000, Top5 = 0.7000
[2017-11-20 18:05:49]:
-Iter 19100, Training Loss= 0.449887, Accuracy Top1 = 0.8500, Top5 = 1.0000
-Iter 19100, Validation Loss= 3.004249, Accuracy Top1 = 0.3750, Top5 = 0.6750
[2017-11-20 18:07:10]:
-Iter 19200, Training Loss= 0.485137, Accuracy Top1 = 0.9000, Top5 = 0.9750
-Iter 19200, Validation Loss= 3.029618, Accuracy Top1 = 0.3875, Top5 = 0.6875
[2017-11-20 18:08:31]:
-Iter 19300, Training Loss= 0.936022, Accuracy Top1 = 0.7250, Top5 = 0.9500
-Iter 19300, Validation Loss= 2.873681, Accuracy Top1 = 0.3750, Top5 = 0.7125
[2017-11-20 18:09:53]:
-Iter 19400, Training Loss= 0.770470, Accuracy Top1 = 0.7250, Top5 = 0.9875
-Iter 19400, Validation Loss= 3.260661, Accuracy Top1 = 0.4500, Top5 = 0.6500
[2017-11-20 18:11:14]:
-Iter 19500, Training Loss= 0.536155, Accuracy Top1 = 0.8250, Top5 = 0.9875
-Iter 19500, Validation Loss= 2.718488, Accuracy Top1 = 0.4250, Top5 = 0.6625
[2017-11-20 18:12:35]:
-Iter 19600, Training Loss= 0.631586, Accuracy Top1 = 0.8000, Top5 = 0.9875
-Iter 19600, Validation Loss= 3.012056, Accuracy Top1 = 0.4000, Top5 = 0.6875
[2017-11-20 18:13:57]:
-Iter 19700, Training Loss= 0.503279, Accuracy Top1 = 0.8625, Top5 = 0.9875
-Iter 19700, Validation Loss= 2.595706, Accuracy Top1 = 0.4625, Top5 = 0.7125
[2017-11-20 18:15:18]:
-Iter 19800, Training Loss= 0.940061, Accuracy Top1 = 0.7375, Top5 = 0.9375
-Iter 19800, Validation Loss= 3.408061, Accuracy Top1 = 0.2875, Top5 = 0.5750
[2017-11-20 18:16:39]:
-Iter 19900, Training Loss= 0.605814, Accuracy Top1 = 0.8125, Top5 = 0.9750
-Iter 19900, Validation Loss= 2.861040, Accuracy Top1 = 0.4375, Top5 = 0.7125
[2017-11-20 18:18:01]:
-Iter 20000, Training Loss= 0.521693, Accuracy Top1 = 0.8375, Top5 = 0.9750
-Iter 20000, Validation Loss= 3.343925, Accuracy Top1 = 0.3000, Top5 = 0.6250
[2017-11-20 18:19:22]:
-Iter 20100, Training Loss= 0.684318, Accuracy Top1 = 0.7375, Top5 = 0.9750
-Iter 20100, Validation Loss= 3.272836, Accuracy Top1 = 0.3250, Top5 = 0.6000
[2017-11-20 18:20:43]:
-Iter 20200, Training Loss= 0.626821, Accuracy Top1 = 0.8375, Top5 = 0.9500
-Iter 20200, Validation Loss= 3.579032, Accuracy Top1 = 0.3625, Top5 = 0.6125
[2017-11-20 18:22:05]:
-Iter 20300, Training Loss= 0.565201, Accuracy Top1 = 0.8750, Top5 = 0.9750
-Iter 20300, Validation Loss= 2.869524, Accuracy Top1 = 0.3625, Top5 = 0.7125
[2017-11-20 18:23:26]:
-Iter 20400, Training Loss= 1.007304, Accuracy Top1 = 0.7125, Top5 = 0.9750
-Iter 20400, Validation Loss= 3.152016, Accuracy Top1 = 0.4125, Top5 = 0.6000
[2017-11-20 18:24:47]:
-Iter 20500, Training Loss= 0.683269, Accuracy Top1 = 0.8125, Top5 = 0.9625
-Iter 20500, Validation Loss= 2.909501, Accuracy Top1 = 0.4125, Top5 = 0.6750
[2017-11-20 18:26:09]:
-Iter 20600, Training Loss= 0.739187, Accuracy Top1 = 0.7750, Top5 = 0.9500
-Iter 20600, Validation Loss= 2.887826, Accuracy Top1 = 0.4500, Top5 = 0.6875
[2017-11-20 18:27:30]:
-Iter 20700, Training Loss= 0.741869, Accuracy Top1 = 0.7625, Top5 = 0.9625
-Iter 20700, Validation Loss= 3.449970, Accuracy Top1 = 0.3500, Top5 = 0.6375
[2017-11-20 18:28:51]:
-Iter 20800, Training Loss= 0.545457, Accuracy Top1 = 0.8375, Top5 = 0.9750
-Iter 20800, Validation Loss= 3.170635, Accuracy Top1 = 0.3500, Top5 = 0.6750
[2017-11-20 18:30:12]:
-Iter 20900, Training Loss= 0.552700, Accuracy Top1 = 0.8500, Top5 = 0.9875
-Iter 20900, Validation Loss= 3.156374, Accuracy Top1 = 0.3375, Top5 = 0.6500
[2017-11-20 18:31:34]:
-Iter 21000, Training Loss= 0.808497, Accuracy Top1 = 0.7250, Top5 = 1.0000
-Iter 21000, Validation Loss= 3.120814, Accuracy Top1 = 0.4375, Top5 = 0.6875
[2017-11-20 18:32:55]:
-Iter 21100, Training Loss= 0.576327, Accuracy Top1 = 0.8000, Top5 = 0.9875
-Iter 21100, Validation Loss= 2.906631, Accuracy Top1 = 0.3875, Top5 = 0.7000
[2017-11-20 18:34:16]:
-Iter 21200, Training Loss= 0.668945, Accuracy Top1 = 0.8375, Top5 = 0.9750
-Iter 21200, Validation Loss= 3.018619, Accuracy Top1 = 0.3250, Top5 = 0.6500
[2017-11-20 18:35:38]:
-Iter 21300, Training Loss= 0.586066, Accuracy Top1 = 0.8125, Top5 = 0.9750
-Iter 21300, Validation Loss= 3.372618, Accuracy Top1 = 0.3500, Top5 = 0.6250
[2017-11-20 18:37:00]:
-Iter 21400, Training Loss= 0.646261, Accuracy Top1 = 0.8875, Top5 = 0.9375
-Iter 21400, Validation Loss= 3.097030, Accuracy Top1 = 0.3375, Top5 = 0.6250
[2017-11-20 18:38:22]:
-Iter 21500, Training Loss= 0.869290, Accuracy Top1 = 0.6750, Top5 = 0.9500
-Iter 21500, Validation Loss= 3.409393, Accuracy Top1 = 0.4125, Top5 = 0.6125
[2017-11-20 18:39:44]:
-Iter 21600, Training Loss= 0.461266, Accuracy Top1 = 0.8750, Top5 = 1.0000
-Iter 21600, Validation Loss= 2.545383, Accuracy Top1 = 0.4750, Top5 = 0.7625
[2017-11-20 18:41:06]:
-Iter 21700, Training Loss= 0.283163, Accuracy Top1 = 0.9125, Top5 = 1.0000
-Iter 21700, Validation Loss= 2.980861, Accuracy Top1 = 0.3500, Top5 = 0.7250
[2017-11-20 18:42:28]:
-Iter 21800, Training Loss= 0.644651, Accuracy Top1 = 0.8125, Top5 = 0.9750
-Iter 21800, Validation Loss= 3.177447, Accuracy Top1 = 0.3875, Top5 = 0.6750
[2017-11-20 18:43:50]:
-Iter 21900, Training Loss= 0.663735, Accuracy Top1 = 0.8000, Top5 = 0.9375
-Iter 21900, Validation Loss= 2.936196, Accuracy Top1 = 0.4000, Top5 = 0.6625
[2017-11-20 18:45:12]:
-Iter 22000, Training Loss= 0.567097, Accuracy Top1 = 0.8125, Top5 = 1.0000
-Iter 22000, Validation Loss= 2.896860, Accuracy Top1 = 0.4500, Top5 = 0.6875
[2017-11-20 18:46:34]:
-Iter 22100, Training Loss= 0.459426, Accuracy Top1 = 0.8625, Top5 = 0.9875
-Iter 22100, Validation Loss= 3.745896, Accuracy Top1 = 0.3250, Top5 = 0.6125
[2017-11-20 18:47:56]:
-Iter 22200, Training Loss= 0.641317, Accuracy Top1 = 0.8000, Top5 = 0.9875
-Iter 22200, Validation Loss= 3.036233, Accuracy Top1 = 0.4000, Top5 = 0.6625
[2017-11-20 18:49:18]:
-Iter 22300, Training Loss= 0.716937, Accuracy Top1 = 0.7750, Top5 = 0.9750
-Iter 22300, Validation Loss= 3.105125, Accuracy Top1 = 0.3750, Top5 = 0.6875
[2017-11-20 18:50:40]:
-Iter 22400, Training Loss= 0.521152, Accuracy Top1 = 0.8750, Top5 = 0.9875
-Iter 22400, Validation Loss= 3.000503, Accuracy Top1 = 0.3750, Top5 = 0.6375
Model saved at Iter 22500 !
[2017-11-20 18:52:03]:
-Iter 22500, Training Loss= 0.396244, Accuracy Top1 = 0.8750, Top5 = 1.0000
-Iter 22500, Validation Loss= 3.791019, Accuracy Top1 = 0.3125, Top5 = 0.5750
[2017-11-20 18:53:25]:
-Iter 22600, Training Loss= 0.550646, Accuracy Top1 = 0.8125, Top5 = 1.0000
-Iter 22600, Validation Loss= 3.193683, Accuracy Top1 = 0.4000, Top5 = 0.7375
[2017-11-20 18:54:47]:
-Iter 22700, Training Loss= 0.819396, Accuracy Top1 = 0.7000, Top5 = 0.9500
-Iter 22700, Validation Loss= 2.723258, Accuracy Top1 = 0.4625, Top5 = 0.6125
[2017-11-20 18:56:09]:
-Iter 22800, Training Loss= 0.420590, Accuracy Top1 = 0.8875, Top5 = 0.9875
-Iter 22800, Validation Loss= 3.681433, Accuracy Top1 = 0.3375, Top5 = 0.6125
[2017-11-20 18:57:30]:
-Iter 22900, Training Loss= 0.513161, Accuracy Top1 = 0.8750, Top5 = 0.9750
-Iter 22900, Validation Loss= 2.670640, Accuracy Top1 = 0.4625, Top5 = 0.7125
[2017-11-20 18:58:51]:
-Iter 23000, Training Loss= 0.582798, Accuracy Top1 = 0.8375, Top5 = 0.9375
-Iter 23000, Validation Loss= 3.198083, Accuracy Top1 = 0.3250, Top5 = 0.6500
[2017-11-20 19:00:13]:
-Iter 23100, Training Loss= 0.436111, Accuracy Top1 = 0.8625, Top5 = 0.9750
-Iter 23100, Validation Loss= 3.526471, Accuracy Top1 = 0.3375, Top5 = 0.5750
[2017-11-20 19:01:34]:
-Iter 23200, Training Loss= 0.420857, Accuracy Top1 = 0.9125, Top5 = 0.9875
-Iter 23200, Validation Loss= 4.062242, Accuracy Top1 = 0.3125, Top5 = 0.6500
[2017-11-20 19:02:55]:
-Iter 23300, Training Loss= 0.341818, Accuracy Top1 = 0.9000, Top5 = 1.0000
-Iter 23300, Validation Loss= 2.749167, Accuracy Top1 = 0.4375, Top5 = 0.6625
[2017-11-20 19:04:17]:
-Iter 23400, Training Loss= 0.507925, Accuracy Top1 = 0.8125, Top5 = 0.9875
-Iter 23400, Validation Loss= 2.653358, Accuracy Top1 = 0.4000, Top5 = 0.7000
[2017-11-20 19:05:38]:
-Iter 23500, Training Loss= 0.384400, Accuracy Top1 = 0.9000, Top5 = 0.9875
-Iter 23500, Validation Loss= 2.434541, Accuracy Top1 = 0.4750, Top5 = 0.7500
[2017-11-20 19:07:00]:
-Iter 23600, Training Loss= 0.402616, Accuracy Top1 = 0.8750, Top5 = 1.0000
-Iter 23600, Validation Loss= 3.217883, Accuracy Top1 = 0.3625, Top5 = 0.6625
[2017-11-20 19:08:22]:
-Iter 23700, Training Loss= 0.328409, Accuracy Top1 = 0.9000, Top5 = 1.0000
-Iter 23700, Validation Loss= 3.049437, Accuracy Top1 = 0.4750, Top5 = 0.6500
[2017-11-20 19:09:44]:
-Iter 23800, Training Loss= 0.439930, Accuracy Top1 = 0.8500, Top5 = 0.9875
-Iter 23800, Validation Loss= 3.306700, Accuracy Top1 = 0.3875, Top5 = 0.6875
[2017-11-20 19:11:07]:
-Iter 23900, Training Loss= 0.329687, Accuracy Top1 = 0.8875, Top5 = 1.0000
-Iter 23900, Validation Loss= 3.493083, Accuracy Top1 = 0.3250, Top5 = 0.6500
[2017-11-20 19:12:29]:
-Iter 24000, Training Loss= 0.704985, Accuracy Top1 = 0.7750, Top5 = 0.9375
-Iter 24000, Validation Loss= 2.719543, Accuracy Top1 = 0.4375, Top5 = 0.7375
[2017-11-20 19:13:51]:
-Iter 24100, Training Loss= 0.377489, Accuracy Top1 = 0.8875, Top5 = 0.9875
-Iter 24100, Validation Loss= 2.836809, Accuracy Top1 = 0.4625, Top5 = 0.7250
[2017-11-20 19:15:13]:
-Iter 24200, Training Loss= 0.564100, Accuracy Top1 = 0.8125, Top5 = 0.9875
-Iter 24200, Validation Loss= 4.495903, Accuracy Top1 = 0.3500, Top5 = 0.5500
[2017-11-20 19:16:35]:
-Iter 24300, Training Loss= 0.578584, Accuracy Top1 = 0.8500, Top5 = 0.9625
-Iter 24300, Validation Loss= 3.837842, Accuracy Top1 = 0.3500, Top5 = 0.5125
[2017-11-20 19:17:56]:
-Iter 24400, Training Loss= 0.602693, Accuracy Top1 = 0.8125, Top5 = 0.9875
-Iter 24400, Validation Loss= 2.968282, Accuracy Top1 = 0.4125, Top5 = 0.7750
[2017-11-20 19:19:19]:
-Iter 24500, Training Loss= 0.447487, Accuracy Top1 = 0.8375, Top5 = 1.0000
-Iter 24500, Validation Loss= 3.106464, Accuracy Top1 = 0.3750, Top5 = 0.7625
[2017-11-20 19:20:40]:
-Iter 24600, Training Loss= 0.352183, Accuracy Top1 = 0.8875, Top5 = 1.0000
-Iter 24600, Validation Loss= 3.565875, Accuracy Top1 = 0.3625, Top5 = 0.6625
[2017-11-20 19:22:02]:
-Iter 24700, Training Loss= 0.417761, Accuracy Top1 = 0.9000, Top5 = 0.9875
-Iter 24700, Validation Loss= 3.268292, Accuracy Top1 = 0.3250, Top5 = 0.6875
[2017-11-20 19:23:24]:
-Iter 24800, Training Loss= 0.442637, Accuracy Top1 = 0.8750, Top5 = 0.9875
-Iter 24800, Validation Loss= 2.580442, Accuracy Top1 = 0.4750, Top5 = 0.7625
[2017-11-20 19:24:46]:
-Iter 24900, Training Loss= 0.454302, Accuracy Top1 = 0.8625, Top5 = 0.9500
-Iter 24900, Validation Loss= 3.250325, Accuracy Top1 = 0.3500, Top5 = 0.6250
[2017-11-20 19:26:08]:
-Iter 25000, Training Loss= 0.462586, Accuracy Top1 = 0.8500, Top5 = 0.9750
-Iter 25000, Validation Loss= 3.404619, Accuracy Top1 = 0.3375, Top5 = 0.6750
[2017-11-20 19:27:30]:
-Iter 25100, Training Loss= 0.620087, Accuracy Top1 = 0.8125, Top5 = 0.9875
-Iter 25100, Validation Loss= 2.776164, Accuracy Top1 = 0.4500, Top5 = 0.7125
[2017-11-20 19:28:52]:
-Iter 25200, Training Loss= 0.607121, Accuracy Top1 = 0.7750, Top5 = 1.0000
-Iter 25200, Validation Loss= 3.495492, Accuracy Top1 = 0.3250, Top5 = 0.6000
[2017-11-20 19:30:15]:
-Iter 25300, Training Loss= 0.410384, Accuracy Top1 = 0.9125, Top5 = 0.9625
-Iter 25300, Validation Loss= 3.631875, Accuracy Top1 = 0.4000, Top5 = 0.6500
[2017-11-20 19:31:37]:
-Iter 25400, Training Loss= 0.646186, Accuracy Top1 = 0.8125, Top5 = 1.0000
-Iter 25400, Validation Loss= 3.015744, Accuracy Top1 = 0.4875, Top5 = 0.7125
[2017-11-20 19:32:59]:
-Iter 25500, Training Loss= 0.533655, Accuracy Top1 = 0.8750, Top5 = 0.9750
-Iter 25500, Validation Loss= 3.900045, Accuracy Top1 = 0.3750, Top5 = 0.6375
[2017-11-20 19:34:21]:
-Iter 25600, Training Loss= 0.375141, Accuracy Top1 = 0.8875, Top5 = 0.9875
-Iter 25600, Validation Loss= 3.490013, Accuracy Top1 = 0.4000, Top5 = 0.6875
[2017-11-20 19:35:43]:
-Iter 25700, Training Loss= 0.292087, Accuracy Top1 = 0.8875, Top5 = 1.0000
-Iter 25700, Validation Loss= 3.397094, Accuracy Top1 = 0.3375, Top5 = 0.6125
[2017-11-20 19:37:05]:
-Iter 25800, Training Loss= 0.368863, Accuracy Top1 = 0.8875, Top5 = 0.9875
-Iter 25800, Validation Loss= 4.120733, Accuracy Top1 = 0.3000, Top5 = 0.5625
[2017-11-20 19:38:27]:
-Iter 25900, Training Loss= 0.406420, Accuracy Top1 = 0.9000, Top5 = 1.0000
-Iter 25900, Validation Loss= 2.377985, Accuracy Top1 = 0.5000, Top5 = 0.7500
[2017-11-20 19:39:49]:
-Iter 26000, Training Loss= 0.603154, Accuracy Top1 = 0.7875, Top5 = 0.9875
-Iter 26000, Validation Loss= 3.222727, Accuracy Top1 = 0.3875, Top5 = 0.6625
[2017-11-20 19:41:11]:
-Iter 26100, Training Loss= 0.210158, Accuracy Top1 = 0.9250, Top5 = 1.0000
-Iter 26100, Validation Loss= 3.559206, Accuracy Top1 = 0.3375, Top5 = 0.6250
[2017-11-20 19:42:33]:
-Iter 26200, Training Loss= 0.339444, Accuracy Top1 = 0.9125, Top5 = 1.0000
-Iter 26200, Validation Loss= 2.881056, Accuracy Top1 = 0.4750, Top5 = 0.7500
[2017-11-20 19:43:55]:
-Iter 26300, Training Loss= 0.300314, Accuracy Top1 = 0.8875, Top5 = 1.0000
-Iter 26300, Validation Loss= 2.794637, Accuracy Top1 = 0.4750, Top5 = 0.7375
[2017-11-20 19:45:17]:
-Iter 26400, Training Loss= 0.358201, Accuracy Top1 = 0.8875, Top5 = 0.9875
-Iter 26400, Validation Loss= 2.927955, Accuracy Top1 = 0.4250, Top5 = 0.6750
[2017-11-20 19:46:39]:
-Iter 26500, Training Loss= 0.631475, Accuracy Top1 = 0.8125, Top5 = 0.9750
-Iter 26500, Validation Loss= 3.010372, Accuracy Top1 = 0.3875, Top5 = 0.7375
[2017-11-20 19:48:01]:
-Iter 26600, Training Loss= 0.277199, Accuracy Top1 = 0.9000, Top5 = 1.0000
-Iter 26600, Validation Loss= 3.772252, Accuracy Top1 = 0.3750, Top5 = 0.6500
[2017-11-20 19:49:23]:
-Iter 26700, Training Loss= 0.431042, Accuracy Top1 = 0.8625, Top5 = 0.9750
-Iter 26700, Validation Loss= 4.059129, Accuracy Top1 = 0.3750, Top5 = 0.6250
[2017-11-20 19:50:45]:
-Iter 26800, Training Loss= 0.392355, Accuracy Top1 = 0.9000, Top5 = 0.9875
-Iter 26800, Validation Loss= 3.606674, Accuracy Top1 = 0.3125, Top5 = 0.6125
[2017-11-20 19:52:07]:
-Iter 26900, Training Loss= 0.365231, Accuracy Top1 = 0.8875, Top5 = 0.9750
-Iter 26900, Validation Loss= 3.614330, Accuracy Top1 = 0.2875, Top5 = 0.6500
[2017-11-20 19:53:29]:
-Iter 27000, Training Loss= 0.244019, Accuracy Top1 = 0.9375, Top5 = 1.0000
-Iter 27000, Validation Loss= 2.842026, Accuracy Top1 = 0.3250, Top5 = 0.7000
[2017-11-20 19:54:51]:
-Iter 27100, Training Loss= 0.436091, Accuracy Top1 = 0.8750, Top5 = 1.0000
-Iter 27100, Validation Loss= 3.294330, Accuracy Top1 = 0.4000, Top5 = 0.7000
[2017-11-20 19:56:13]:
-Iter 27200, Training Loss= 0.330423, Accuracy Top1 = 0.8500, Top5 = 1.0000
-Iter 27200, Validation Loss= 3.023923, Accuracy Top1 = 0.4375, Top5 = 0.6750
[2017-11-20 19:57:35]:
-Iter 27300, Training Loss= 0.391087, Accuracy Top1 = 0.8875, Top5 = 0.9875
-Iter 27300, Validation Loss= 4.056756, Accuracy Top1 = 0.3625, Top5 = 0.5875
[2017-11-20 19:58:57]:
-Iter 27400, Training Loss= 0.319675, Accuracy Top1 = 0.9125, Top5 = 1.0000
-Iter 27400, Validation Loss= 4.778522, Accuracy Top1 = 0.3875, Top5 = 0.6000
[2017-11-20 20:00:19]:
-Iter 27500, Training Loss= 0.302901, Accuracy Top1 = 0.9250, Top5 = 1.0000
-Iter 27500, Validation Loss= 3.648359, Accuracy Top1 = 0.4375, Top5 = 0.6750
[2017-11-20 20:01:41]:
-Iter 27600, Training Loss= 0.311650, Accuracy Top1 = 0.9000, Top5 = 0.9750
-Iter 27600, Validation Loss= 3.259949, Accuracy Top1 = 0.2875, Top5 = 0.7000
[2017-11-20 20:03:03]:
-Iter 27700, Training Loss= 0.341601, Accuracy Top1 = 0.8875, Top5 = 1.0000
-Iter 27700, Validation Loss= 2.938039, Accuracy Top1 = 0.3125, Top5 = 0.6750
[2017-11-20 20:04:25]:
-Iter 27800, Training Loss= 0.389804, Accuracy Top1 = 0.8875, Top5 = 0.9875
-Iter 27800, Validation Loss= 3.295746, Accuracy Top1 = 0.4000, Top5 = 0.7000
[2017-11-20 20:05:47]:
-Iter 27900, Training Loss= 0.411348, Accuracy Top1 = 0.9000, Top5 = 0.9625
-Iter 27900, Validation Loss= 3.671772, Accuracy Top1 = 0.3875, Top5 = 0.6750
[2017-11-20 20:07:09]:
-Iter 28000, Training Loss= 0.438333, Accuracy Top1 = 0.8375, Top5 = 1.0000
-Iter 28000, Validation Loss= 4.087983, Accuracy Top1 = 0.3250, Top5 = 0.6375
[2017-11-20 20:08:31]:
-Iter 28100, Training Loss= 0.303850, Accuracy Top1 = 0.9000, Top5 = 1.0000
-Iter 28100, Validation Loss= 3.533241, Accuracy Top1 = 0.3375, Top5 = 0.6125
[2017-11-20 20:09:53]:
-Iter 28200, Training Loss= 0.330137, Accuracy Top1 = 0.8625, Top5 = 1.0000
-Iter 28200, Validation Loss= 2.571344, Accuracy Top1 = 0.4375, Top5 = 0.7875
[2017-11-20 20:11:15]:
-Iter 28300, Training Loss= 0.282724, Accuracy Top1 = 0.9000, Top5 = 1.0000
-Iter 28300, Validation Loss= 3.832114, Accuracy Top1 = 0.3625, Top5 = 0.6250
[2017-11-20 20:12:37]:
-Iter 28400, Training Loss= 0.302036, Accuracy Top1 = 0.9250, Top5 = 0.9875
-Iter 28400, Validation Loss= 3.076356, Accuracy Top1 = 0.4625, Top5 = 0.6875
[2017-11-20 20:13:59]:
-Iter 28500, Training Loss= 0.443369, Accuracy Top1 = 0.8875, Top5 = 0.9500
-Iter 28500, Validation Loss= 3.271493, Accuracy Top1 = 0.4250, Top5 = 0.6625
[2017-11-20 20:15:21]:
-Iter 28600, Training Loss= 0.348503, Accuracy Top1 = 0.8750, Top5 = 1.0000
-Iter 28600, Validation Loss= 3.132494, Accuracy Top1 = 0.3625, Top5 = 0.7125
[2017-11-20 20:16:42]:
-Iter 28700, Training Loss= 0.372328, Accuracy Top1 = 0.9125, Top5 = 0.9875
-Iter 28700, Validation Loss= 2.967442, Accuracy Top1 = 0.3875, Top5 = 0.7000
[2017-11-20 20:18:03]:
-Iter 28800, Training Loss= 0.260004, Accuracy Top1 = 0.9125, Top5 = 1.0000
-Iter 28800, Validation Loss= 3.407506, Accuracy Top1 = 0.3250, Top5 = 0.6875
[2017-11-20 20:19:25]:
-Iter 28900, Training Loss= 0.393621, Accuracy Top1 = 0.8875, Top5 = 1.0000
-Iter 28900, Validation Loss= 4.180848, Accuracy Top1 = 0.3625, Top5 = 0.6375
[2017-11-20 20:20:46]:
-Iter 29000, Training Loss= 0.404722, Accuracy Top1 = 0.9125, Top5 = 0.9750
-Iter 29000, Validation Loss= 3.630198, Accuracy Top1 = 0.3500, Top5 = 0.5750
[2017-11-20 20:22:07]:
-Iter 29100, Training Loss= 0.188020, Accuracy Top1 = 0.9500, Top5 = 0.9875
-Iter 29100, Validation Loss= 3.319288, Accuracy Top1 = 0.4375, Top5 = 0.7250
[2017-11-20 20:23:29]:
-Iter 29200, Training Loss= 0.219819, Accuracy Top1 = 0.9500, Top5 = 1.0000
-Iter 29200, Validation Loss= 3.723514, Accuracy Top1 = 0.3250, Top5 = 0.6000
[2017-11-20 20:24:50]:
-Iter 29300, Training Loss= 0.288808, Accuracy Top1 = 0.8875, Top5 = 1.0000
-Iter 29300, Validation Loss= 3.571571, Accuracy Top1 = 0.4000, Top5 = 0.7125
[2017-11-20 20:26:12]:
-Iter 29400, Training Loss= 0.290686, Accuracy Top1 = 0.9125, Top5 = 0.9875
-Iter 29400, Validation Loss= 3.910373, Accuracy Top1 = 0.3500, Top5 = 0.6125
[2017-11-20 20:27:33]:
-Iter 29500, Training Loss= 0.191349, Accuracy Top1 = 0.9500, Top5 = 1.0000
-Iter 29500, Validation Loss= 3.461912, Accuracy Top1 = 0.3875, Top5 = 0.6250
[2017-11-20 20:28:54]:
-Iter 29600, Training Loss= 0.196147, Accuracy Top1 = 0.9375, Top5 = 1.0000
-Iter 29600, Validation Loss= 3.277277, Accuracy Top1 = 0.4500, Top5 = 0.6750
[2017-11-20 20:30:16]:
-Iter 29700, Training Loss= 0.217357, Accuracy Top1 = 0.9625, Top5 = 1.0000
-Iter 29700, Validation Loss= 3.205472, Accuracy Top1 = 0.4500, Top5 = 0.7375
[2017-11-20 20:31:37]:
-Iter 29800, Training Loss= 0.258852, Accuracy Top1 = 0.9375, Top5 = 1.0000
-Iter 29800, Validation Loss= 3.559443, Accuracy Top1 = 0.4000, Top5 = 0.6750
[2017-11-20 20:32:58]:
-Iter 29900, Training Loss= 0.239971, Accuracy Top1 = 0.9375, Top5 = 0.9875
-Iter 29900, Validation Loss= 3.062342, Accuracy Top1 = 0.3750, Top5 = 0.7375
Model saved at Iter 30000 !
[2017-11-20 20:34:21]:
-Iter 30000, Training Loss= 0.269957, Accuracy Top1 = 0.9500, Top5 = 0.9875
-Iter 30000, Validation Loss= 3.896837, Accuracy Top1 = 0.3125, Top5 = 0.6000
[2017-11-20 20:35:42]:
-Iter 30100, Training Loss= 0.250490, Accuracy Top1 = 0.9000, Top5 = 1.0000
-Iter 30100, Validation Loss= 3.220114, Accuracy Top1 = 0.3750, Top5 = 0.7000
[2017-11-20 20:37:04]:
-Iter 30200, Training Loss= 0.399582, Accuracy Top1 = 0.9125, Top5 = 1.0000
-Iter 30200, Validation Loss= 3.602788, Accuracy Top1 = 0.3750, Top5 = 0.6625
[2017-11-20 20:38:26]:
-Iter 30300, Training Loss= 0.463047, Accuracy Top1 = 0.8625, Top5 = 0.9625
-Iter 30300, Validation Loss= 3.324606, Accuracy Top1 = 0.3875, Top5 = 0.6375
[2017-11-20 20:39:48]:
-Iter 30400, Training Loss= 0.388149, Accuracy Top1 = 0.8875, Top5 = 0.9875
-Iter 30400, Validation Loss= 3.001312, Accuracy Top1 = 0.4250, Top5 = 0.7375
[2017-11-20 20:41:10]:
-Iter 30500, Training Loss= 0.400584, Accuracy Top1 = 0.8625, Top5 = 1.0000
-Iter 30500, Validation Loss= 3.711226, Accuracy Top1 = 0.3750, Top5 = 0.6875
[2017-11-20 20:42:32]:
-Iter 30600, Training Loss= 0.376421, Accuracy Top1 = 0.9125, Top5 = 0.9750
-Iter 30600, Validation Loss= 3.396856, Accuracy Top1 = 0.3500, Top5 = 0.7000
[2017-11-20 20:43:55]:
-Iter 30700, Training Loss= 0.161464, Accuracy Top1 = 0.9750, Top5 = 1.0000
-Iter 30700, Validation Loss= 3.374998, Accuracy Top1 = 0.3750, Top5 = 0.6250
[2017-11-20 20:45:17]:
-Iter 30800, Training Loss= 0.300697, Accuracy Top1 = 0.9000, Top5 = 1.0000
-Iter 30800, Validation Loss= 3.342348, Accuracy Top1 = 0.3375, Top5 = 0.6875
[2017-11-20 20:46:39]:
-Iter 30900, Training Loss= 0.398329, Accuracy Top1 = 0.8875, Top5 = 1.0000
-Iter 30900, Validation Loss= 3.670547, Accuracy Top1 = 0.3750, Top5 = 0.6250
[2017-11-20 20:48:01]:
-Iter 31000, Training Loss= 0.401802, Accuracy Top1 = 0.9000, Top5 = 0.9750
-Iter 31000, Validation Loss= 3.729211, Accuracy Top1 = 0.3250, Top5 = 0.6750
[2017-11-20 20:49:23]:
-Iter 31100, Training Loss= 0.217619, Accuracy Top1 = 0.9250, Top5 = 1.0000
-Iter 31100, Validation Loss= 2.718532, Accuracy Top1 = 0.4500, Top5 = 0.8000
[2017-11-20 20:50:45]:
-Iter 31200, Training Loss= 0.306864, Accuracy Top1 = 0.9000, Top5 = 1.0000
-Iter 31200, Validation Loss= 4.564687, Accuracy Top1 = 0.3125, Top5 = 0.5875
[2017-11-20 20:52:07]:
-Iter 31300, Training Loss= 0.344561, Accuracy Top1 = 0.9000, Top5 = 1.0000
-Iter 31300, Validation Loss= 3.557063, Accuracy Top1 = 0.3750, Top5 = 0.6875
[2017-11-20 20:53:29]:
-Iter 31400, Training Loss= 0.319678, Accuracy Top1 = 0.9125, Top5 = 0.9875
-Iter 31400, Validation Loss= 3.186716, Accuracy Top1 = 0.4500, Top5 = 0.7000
[2017-11-20 20:54:51]:
-Iter 31500, Training Loss= 0.308251, Accuracy Top1 = 0.9125, Top5 = 1.0000
-Iter 31500, Validation Loss= 3.292551, Accuracy Top1 = 0.3750, Top5 = 0.6750
[2017-11-20 20:56:12]:
-Iter 31600, Training Loss= 0.195683, Accuracy Top1 = 0.9750, Top5 = 1.0000
-Iter 31600, Validation Loss= 2.889310, Accuracy Top1 = 0.4625, Top5 = 0.6625
[2017-11-20 20:57:34]:
-Iter 31700, Training Loss= 0.227853, Accuracy Top1 = 0.9375, Top5 = 1.0000
-Iter 31700, Validation Loss= 3.334072, Accuracy Top1 = 0.3750, Top5 = 0.7000
[2017-11-20 20:58:55]:
-Iter 31800, Training Loss= 0.237852, Accuracy Top1 = 0.9250, Top5 = 1.0000
-Iter 31800, Validation Loss= 2.935263, Accuracy Top1 = 0.4250, Top5 = 0.7500
[2017-11-20 21:00:16]:
-Iter 31900, Training Loss= 0.213523, Accuracy Top1 = 0.9500, Top5 = 0.9875
-Iter 31900, Validation Loss= 3.742206, Accuracy Top1 = 0.4125, Top5 = 0.6750
[2017-11-20 21:01:38]:
-Iter 32000, Training Loss= 0.343444, Accuracy Top1 = 0.9125, Top5 = 1.0000
-Iter 32000, Validation Loss= 3.212172, Accuracy Top1 = 0.3750, Top5 = 0.7000
[2017-11-20 21:02:59]:
-Iter 32100, Training Loss= 0.214947, Accuracy Top1 = 0.9375, Top5 = 1.0000
-Iter 32100, Validation Loss= 3.198897, Accuracy Top1 = 0.4250, Top5 = 0.6875
[2017-11-20 21:04:20]:
-Iter 32200, Training Loss= 0.291270, Accuracy Top1 = 0.9375, Top5 = 0.9875
-Iter 32200, Validation Loss= 2.896767, Accuracy Top1 = 0.4000, Top5 = 0.7500
[2017-11-20 21:05:42]:
-Iter 32300, Training Loss= 0.155565, Accuracy Top1 = 0.9625, Top5 = 1.0000
-Iter 32300, Validation Loss= 3.695327, Accuracy Top1 = 0.3875, Top5 = 0.6625
[2017-11-20 21:07:04]:
-Iter 32400, Training Loss= 0.232666, Accuracy Top1 = 0.9375, Top5 = 1.0000
-Iter 32400, Validation Loss= 2.986366, Accuracy Top1 = 0.4500, Top5 = 0.7000
[2017-11-20 21:08:26]:
-Iter 32500, Training Loss= 0.336144, Accuracy Top1 = 0.8750, Top5 = 1.0000
-Iter 32500, Validation Loss= 3.469822, Accuracy Top1 = 0.3375, Top5 = 0.7000
[2017-11-20 21:09:48]:
-Iter 32600, Training Loss= 0.210433, Accuracy Top1 = 0.9125, Top5 = 1.0000
-Iter 32600, Validation Loss= 3.586784, Accuracy Top1 = 0.3250, Top5 = 0.6000
[2017-11-20 21:11:10]:
-Iter 32700, Training Loss= 0.206298, Accuracy Top1 = 0.9375, Top5 = 1.0000
-Iter 32700, Validation Loss= 4.106716, Accuracy Top1 = 0.3125, Top5 = 0.6250
[2017-11-20 21:12:32]:
-Iter 32800, Training Loss= 0.298466, Accuracy Top1 = 0.9125, Top5 = 0.9875
-Iter 32800, Validation Loss= 3.108777, Accuracy Top1 = 0.3750, Top5 = 0.7375
[2017-11-20 21:13:54]:
-Iter 32900, Training Loss= 0.372347, Accuracy Top1 = 0.8875, Top5 = 1.0000
-Iter 32900, Validation Loss= 3.338252, Accuracy Top1 = 0.3750, Top5 = 0.6250
[2017-11-20 21:15:16]:
-Iter 33000, Training Loss= 0.273157, Accuracy Top1 = 0.9375, Top5 = 0.9875
-Iter 33000, Validation Loss= 3.376927, Accuracy Top1 = 0.3875, Top5 = 0.6625
[2017-11-20 21:16:38]:
-Iter 33100, Training Loss= 0.283377, Accuracy Top1 = 0.8875, Top5 = 0.9875
-Iter 33100, Validation Loss= 2.816582, Accuracy Top1 = 0.4500, Top5 = 0.7375
[2017-11-20 21:18:00]:
-Iter 33200, Training Loss= 0.190041, Accuracy Top1 = 0.9500, Top5 = 1.0000
-Iter 33200, Validation Loss= 4.115026, Accuracy Top1 = 0.3875, Top5 = 0.6875
[2017-11-20 21:19:22]:
-Iter 33300, Training Loss= 0.242472, Accuracy Top1 = 0.9125, Top5 = 1.0000
-Iter 33300, Validation Loss= 4.412311, Accuracy Top1 = 0.3250, Top5 = 0.5750
[2017-11-20 21:20:44]:
-Iter 33400, Training Loss= 0.365362, Accuracy Top1 = 0.8500, Top5 = 0.9750
-Iter 33400, Validation Loss= 3.791610, Accuracy Top1 = 0.3250, Top5 = 0.6375
[2017-11-20 21:22:06]:
-Iter 33500, Training Loss= 0.301464, Accuracy Top1 = 0.9125, Top5 = 1.0000
-Iter 33500, Validation Loss= 3.180008, Accuracy Top1 = 0.3875, Top5 = 0.7625
[2017-11-20 21:23:28]:
-Iter 33600, Training Loss= 0.274546, Accuracy Top1 = 0.9125, Top5 = 1.0000
-Iter 33600, Validation Loss= 3.051857, Accuracy Top1 = 0.4250, Top5 = 0.7375
[2017-11-20 21:24:51]:
-Iter 33700, Training Loss= 0.250603, Accuracy Top1 = 0.9500, Top5 = 0.9875
-Iter 33700, Validation Loss= 3.296434, Accuracy Top1 = 0.4250, Top5 = 0.7000
[2017-11-20 21:26:13]:
-Iter 33800, Training Loss= 0.233746, Accuracy Top1 = 0.9000, Top5 = 0.9875
-Iter 33800, Validation Loss= 3.555114, Accuracy Top1 = 0.3250, Top5 = 0.6625
[2017-11-20 21:27:35]:
-Iter 33900, Training Loss= 0.162108, Accuracy Top1 = 0.9375, Top5 = 1.0000
-Iter 33900, Validation Loss= 3.730033, Accuracy Top1 = 0.3625, Top5 = 0.6250
[2017-11-20 21:28:57]:
-Iter 34000, Training Loss= 0.420424, Accuracy Top1 = 0.8875, Top5 = 0.9875
-Iter 34000, Validation Loss= 3.581833, Accuracy Top1 = 0.3625, Top5 = 0.6500
[2017-11-20 21:30:19]:
-Iter 34100, Training Loss= 0.175666, Accuracy Top1 = 0.9375, Top5 = 1.0000
-Iter 34100, Validation Loss= 2.615713, Accuracy Top1 = 0.4875, Top5 = 0.8000
[2017-11-20 21:31:41]:
-Iter 34200, Training Loss= 0.242189, Accuracy Top1 = 0.9375, Top5 = 0.9875
-Iter 34200, Validation Loss= 3.205662, Accuracy Top1 = 0.3875, Top5 = 0.6875
[2017-11-20 21:33:03]:
-Iter 34300, Training Loss= 0.125471, Accuracy Top1 = 0.9500, Top5 = 1.0000
-Iter 34300, Validation Loss= 3.409133, Accuracy Top1 = 0.4125, Top5 = 0.6875
[2017-11-20 21:34:25]:
-Iter 34400, Training Loss= 0.391582, Accuracy Top1 = 0.8625, Top5 = 0.9875
-Iter 34400, Validation Loss= 3.285669, Accuracy Top1 = 0.4625, Top5 = 0.6875
[2017-11-20 21:35:47]:
-Iter 34500, Training Loss= 0.213221, Accuracy Top1 = 0.9375, Top5 = 1.0000
-Iter 34500, Validation Loss= 3.277876, Accuracy Top1 = 0.3875, Top5 = 0.7375
[2017-11-20 21:37:09]:
-Iter 34600, Training Loss= 0.351553, Accuracy Top1 = 0.9000, Top5 = 0.9875
-Iter 34600, Validation Loss= 3.994918, Accuracy Top1 = 0.3125, Top5 = 0.6000
[2017-11-20 21:38:31]:
-Iter 34700, Training Loss= 0.220727, Accuracy Top1 = 0.9500, Top5 = 1.0000
-Iter 34700, Validation Loss= 3.004786, Accuracy Top1 = 0.3250, Top5 = 0.7000
[2017-11-20 21:39:53]:
-Iter 34800, Training Loss= 0.300326, Accuracy Top1 = 0.9000, Top5 = 0.9875
-Iter 34800, Validation Loss= 3.700301, Accuracy Top1 = 0.4375, Top5 = 0.6750
[2017-11-20 21:41:15]:
-Iter 34900, Training Loss= 0.310552, Accuracy Top1 = 0.9250, Top5 = 1.0000
-Iter 34900, Validation Loss= 3.285981, Accuracy Top1 = 0.4125, Top5 = 0.6500
[2017-11-20 21:42:37]:
-Iter 35000, Training Loss= 0.295278, Accuracy Top1 = 0.9125, Top5 = 1.0000
-Iter 35000, Validation Loss= 4.402144, Accuracy Top1 = 0.2875, Top5 = 0.6250
[2017-11-20 21:43:59]:
-Iter 35100, Training Loss= 0.159344, Accuracy Top1 = 0.9625, Top5 = 1.0000
-Iter 35100, Validation Loss= 3.558713, Accuracy Top1 = 0.4875, Top5 = 0.6750
[2017-11-20 21:45:22]:
-Iter 35200, Training Loss= 0.134291, Accuracy Top1 = 0.9750, Top5 = 1.0000
-Iter 35200, Validation Loss= 3.045449, Accuracy Top1 = 0.4875, Top5 = 0.6625
[2017-11-20 21:46:43]:
-Iter 35300, Training Loss= 0.243522, Accuracy Top1 = 0.9375, Top5 = 1.0000
-Iter 35300, Validation Loss= 3.567449, Accuracy Top1 = 0.3625, Top5 = 0.6625
[2017-11-20 21:48:04]:
-Iter 35400, Training Loss= 0.173717, Accuracy Top1 = 0.9500, Top5 = 1.0000
-Iter 35400, Validation Loss= 2.719995, Accuracy Top1 = 0.4500, Top5 = 0.7250
[2017-11-20 21:49:26]:
-Iter 35500, Training Loss= 0.329416, Accuracy Top1 = 0.9250, Top5 = 0.9875
-Iter 35500, Validation Loss= 3.622658, Accuracy Top1 = 0.3625, Top5 = 0.6875
[2017-11-20 21:50:47]:
-Iter 35600, Training Loss= 0.240812, Accuracy Top1 = 0.9375, Top5 = 0.9875
-Iter 35600, Validation Loss= 3.566317, Accuracy Top1 = 0.3250, Top5 = 0.6375
[2017-11-20 21:52:08]:
-Iter 35700, Training Loss= 0.161325, Accuracy Top1 = 0.9500, Top5 = 1.0000
-Iter 35700, Validation Loss= 3.448248, Accuracy Top1 = 0.4000, Top5 = 0.6875
[2017-11-20 21:53:30]:
-Iter 35800, Training Loss= 0.259333, Accuracy Top1 = 0.9250, Top5 = 1.0000
-Iter 35800, Validation Loss= 2.965999, Accuracy Top1 = 0.4000, Top5 = 0.6625
[2017-11-20 21:54:51]:
-Iter 35900, Training Loss= 0.311895, Accuracy Top1 = 0.9125, Top5 = 0.9875
-Iter 35900, Validation Loss= 3.251118, Accuracy Top1 = 0.4250, Top5 = 0.7000
[2017-11-20 21:56:12]:
-Iter 36000, Training Loss= 0.399231, Accuracy Top1 = 0.8750, Top5 = 0.9750
-Iter 36000, Validation Loss= 2.909726, Accuracy Top1 = 0.4875, Top5 = 0.7750
[2017-11-20 21:57:34]:
-Iter 36100, Training Loss= 0.252481, Accuracy Top1 = 0.9250, Top5 = 0.9875
-Iter 36100, Validation Loss= 3.367412, Accuracy Top1 = 0.4250, Top5 = 0.7375
[2017-11-20 21:58:55]:
-Iter 36200, Training Loss= 0.157049, Accuracy Top1 = 0.9500, Top5 = 1.0000
-Iter 36200, Validation Loss= 3.484914, Accuracy Top1 = 0.4375, Top5 = 0.7250
[2017-11-20 22:00:16]:
-Iter 36300, Training Loss= 0.150085, Accuracy Top1 = 0.9750, Top5 = 0.9875
-Iter 36300, Validation Loss= 3.210814, Accuracy Top1 = 0.4375, Top5 = 0.7250
[2017-11-20 22:01:38]:
-Iter 36400, Training Loss= 0.334699, Accuracy Top1 = 0.9250, Top5 = 0.9625
-Iter 36400, Validation Loss= 3.909836, Accuracy Top1 = 0.3125, Top5 = 0.6625
[2017-11-20 22:02:59]:
-Iter 36500, Training Loss= 0.319650, Accuracy Top1 = 0.9125, Top5 = 0.9875
-Iter 36500, Validation Loss= 3.467716, Accuracy Top1 = 0.4000, Top5 = 0.7750
[2017-11-20 22:04:20]:
-Iter 36600, Training Loss= 0.214568, Accuracy Top1 = 0.9375, Top5 = 1.0000
-Iter 36600, Validation Loss= 3.226751, Accuracy Top1 = 0.4000, Top5 = 0.7375
[2017-11-20 22:05:42]:
-Iter 36700, Training Loss= 0.246008, Accuracy Top1 = 0.9500, Top5 = 0.9875
-Iter 36700, Validation Loss= 4.793401, Accuracy Top1 = 0.3500, Top5 = 0.6000
[2017-11-20 22:07:03]:
-Iter 36800, Training Loss= 0.151161, Accuracy Top1 = 0.9500, Top5 = 1.0000
-Iter 36800, Validation Loss= 3.709229, Accuracy Top1 = 0.4250, Top5 = 0.6000
[2017-11-20 22:08:25]:
-Iter 36900, Training Loss= 0.258231, Accuracy Top1 = 0.9125, Top5 = 1.0000
-Iter 36900, Validation Loss= 3.220573, Accuracy Top1 = 0.4500, Top5 = 0.7250
[2017-11-20 22:09:46]:
-Iter 37000, Training Loss= 0.232066, Accuracy Top1 = 0.9125, Top5 = 1.0000
-Iter 37000, Validation Loss= 3.745373, Accuracy Top1 = 0.3625, Top5 = 0.6625
[2017-11-20 22:11:07]:
-Iter 37100, Training Loss= 0.216784, Accuracy Top1 = 0.9500, Top5 = 1.0000
-Iter 37100, Validation Loss= 3.843661, Accuracy Top1 = 0.3875, Top5 = 0.6125
[2017-11-20 22:12:29]:
-Iter 37200, Training Loss= 0.150866, Accuracy Top1 = 0.9625, Top5 = 1.0000
-Iter 37200, Validation Loss= 3.433645, Accuracy Top1 = 0.4375, Top5 = 0.7000
[2017-11-20 22:13:50]:
-Iter 37300, Training Loss= 0.111848, Accuracy Top1 = 0.9875, Top5 = 1.0000
-Iter 37300, Validation Loss= 3.001518, Accuracy Top1 = 0.4875, Top5 = 0.7625
[2017-11-20 22:15:12]:
-Iter 37400, Training Loss= 0.169819, Accuracy Top1 = 0.9500, Top5 = 1.0000
-Iter 37400, Validation Loss= 3.284363, Accuracy Top1 = 0.3375, Top5 = 0.6250
Model saved at Iter 37500 !
[2017-11-20 22:16:34]:
-Iter 37500, Training Loss= 0.252408, Accuracy Top1 = 0.9125, Top5 = 0.9875
-Iter 37500, Validation Loss= 3.846002, Accuracy Top1 = 0.3625, Top5 = 0.6750
[2017-11-20 22:17:55]:
-Iter 37600, Training Loss= 0.135933, Accuracy Top1 = 0.9750, Top5 = 1.0000
-Iter 37600, Validation Loss= 3.283482, Accuracy Top1 = 0.4375, Top5 = 0.7000
[2017-11-20 22:19:16]:
-Iter 37700, Training Loss= 0.244358, Accuracy Top1 = 0.9625, Top5 = 1.0000
-Iter 37700, Validation Loss= 3.827381, Accuracy Top1 = 0.3750, Top5 = 0.6250
[2017-11-20 22:20:38]:
-Iter 37800, Training Loss= 0.217917, Accuracy Top1 = 0.9250, Top5 = 1.0000
-Iter 37800, Validation Loss= 3.616449, Accuracy Top1 = 0.3625, Top5 = 0.5875
[2017-11-20 22:21:59]:
-Iter 37900, Training Loss= 0.190018, Accuracy Top1 = 0.9375, Top5 = 1.0000
-Iter 37900, Validation Loss= 3.319682, Accuracy Top1 = 0.4750, Top5 = 0.7125
[2017-11-20 22:23:20]:
-Iter 38000, Training Loss= 0.298461, Accuracy Top1 = 0.8875, Top5 = 1.0000
-Iter 38000, Validation Loss= 4.615680, Accuracy Top1 = 0.3375, Top5 = 0.5625
[2017-11-20 22:24:41]:
-Iter 38100, Training Loss= 0.221506, Accuracy Top1 = 0.9250, Top5 = 0.9750
-Iter 38100, Validation Loss= 4.104145, Accuracy Top1 = 0.4250, Top5 = 0.6625
[2017-11-20 22:26:03]:
-Iter 38200, Training Loss= 0.196978, Accuracy Top1 = 0.9500, Top5 = 1.0000
-Iter 38200, Validation Loss= 3.535259, Accuracy Top1 = 0.4000, Top5 = 0.6500
[2017-11-20 22:27:25]:
-Iter 38300, Training Loss= 0.140645, Accuracy Top1 = 0.9750, Top5 = 1.0000
-Iter 38300, Validation Loss= 4.509460, Accuracy Top1 = 0.3750, Top5 = 0.5500
[2017-11-20 22:28:47]:
-Iter 38400, Training Loss= 0.267618, Accuracy Top1 = 0.9125, Top5 = 0.9875
-Iter 38400, Validation Loss= 2.749565, Accuracy Top1 = 0.5250, Top5 = 0.7625
[2017-11-20 22:30:09]:
-Iter 38500, Training Loss= 0.155541, Accuracy Top1 = 0.9250, Top5 = 1.0000
-Iter 38500, Validation Loss= 4.078907, Accuracy Top1 = 0.3750, Top5 = 0.7000
[2017-11-20 22:31:31]:
-Iter 38600, Training Loss= 0.212057, Accuracy Top1 = 0.9250, Top5 = 1.0000
-Iter 38600, Validation Loss= 4.320975, Accuracy Top1 = 0.2750, Top5 = 0.5625
[2017-11-20 22:32:53]:
-Iter 38700, Training Loss= 0.277843, Accuracy Top1 = 0.9250, Top5 = 1.0000
-Iter 38700, Validation Loss= 3.467400, Accuracy Top1 = 0.4625, Top5 = 0.6625
[2017-11-20 22:34:15]:
-Iter 38800, Training Loss= 0.160382, Accuracy Top1 = 0.9375, Top5 = 1.0000
-Iter 38800, Validation Loss= 3.305284, Accuracy Top1 = 0.4500, Top5 = 0.6750
[2017-11-20 22:35:37]:
-Iter 38900, Training Loss= 0.153063, Accuracy Top1 = 0.9500, Top5 = 1.0000
-Iter 38900, Validation Loss= 3.615647, Accuracy Top1 = 0.3625, Top5 = 0.6625
[2017-11-20 22:36:59]:
-Iter 39000, Training Loss= 0.202106, Accuracy Top1 = 0.9375, Top5 = 1.0000
-Iter 39000, Validation Loss= 3.209345, Accuracy Top1 = 0.4375, Top5 = 0.7000
[2017-11-20 22:38:20]:
-Iter 39100, Training Loss= 0.100746, Accuracy Top1 = 0.9625, Top5 = 1.0000
-Iter 39100, Validation Loss= 4.173321, Accuracy Top1 = 0.4000, Top5 = 0.5875
[2017-11-20 22:39:41]:
-Iter 39200, Training Loss= 0.149018, Accuracy Top1 = 0.9375, Top5 = 1.0000
-Iter 39200, Validation Loss= 3.958353, Accuracy Top1 = 0.3625, Top5 = 0.6500
[2017-11-20 22:41:03]:
-Iter 39300, Training Loss= 0.246411, Accuracy Top1 = 0.9375, Top5 = 1.0000
-Iter 39300, Validation Loss= 3.354885, Accuracy Top1 = 0.4000, Top5 = 0.6625
[2017-11-20 22:42:24]:
-Iter 39400, Training Loss= 0.299189, Accuracy Top1 = 0.9125, Top5 = 0.9875
-Iter 39400, Validation Loss= 3.809693, Accuracy Top1 = 0.3125, Top5 = 0.6500
[2017-11-20 22:43:45]:
-Iter 39500, Training Loss= 0.246811, Accuracy Top1 = 0.9375, Top5 = 1.0000
-Iter 39500, Validation Loss= 3.310069, Accuracy Top1 = 0.3625, Top5 = 0.6875
[2017-11-20 22:45:07]:
-Iter 39600, Training Loss= 0.221282, Accuracy Top1 = 0.9375, Top5 = 1.0000
-Iter 39600, Validation Loss= 3.422330, Accuracy Top1 = 0.4375, Top5 = 0.7000
[2017-11-20 22:46:28]:
-Iter 39700, Training Loss= 0.142511, Accuracy Top1 = 0.9625, Top5 = 1.0000
-Iter 39700, Validation Loss= 3.057004, Accuracy Top1 = 0.4750, Top5 = 0.7375
[2017-11-20 22:47:51]:
-Iter 39800, Training Loss= 0.091923, Accuracy Top1 = 1.0000, Top5 = 1.0000
-Iter 39800, Validation Loss= 4.512221, Accuracy Top1 = 0.3625, Top5 = 0.5625
[2017-11-20 22:49:12]:
-Iter 39900, Training Loss= 0.166646, Accuracy Top1 = 0.9250, Top5 = 1.0000
-Iter 39900, Validation Loss= 4.997043, Accuracy Top1 = 0.3000, Top5 = 0.5625
[2017-11-20 22:50:35]:
-Iter 40000, Training Loss= 0.210707, Accuracy Top1 = 0.9375, Top5 = 1.0000
-Iter 40000, Validation Loss= 3.590253, Accuracy Top1 = 0.4125, Top5 = 0.6625
[2017-11-20 22:51:57]:
-Iter 40100, Training Loss= 0.121661, Accuracy Top1 = 0.9625, Top5 = 1.0000
-Iter 40100, Validation Loss= 3.517224, Accuracy Top1 = 0.3375, Top5 = 0.6375
[2017-11-20 22:53:19]:
-Iter 40200, Training Loss= 0.112530, Accuracy Top1 = 0.9875, Top5 = 1.0000
-Iter 40200, Validation Loss= 2.675783, Accuracy Top1 = 0.4000, Top5 = 0.7750
[2017-11-20 22:54:41]:
-Iter 40300, Training Loss= 0.242232, Accuracy Top1 = 0.9375, Top5 = 1.0000
-Iter 40300, Validation Loss= 3.389545, Accuracy Top1 = 0.4000, Top5 = 0.6875
[2017-11-20 22:56:03]:
-Iter 40400, Training Loss= 0.263444, Accuracy Top1 = 0.9375, Top5 = 1.0000
-Iter 40400, Validation Loss= 3.993480, Accuracy Top1 = 0.4000, Top5 = 0.6375
[2017-11-20 22:57:24]:
-Iter 40500, Training Loss= 0.211471, Accuracy Top1 = 0.9375, Top5 = 1.0000
-Iter 40500, Validation Loss= 3.910044, Accuracy Top1 = 0.3625, Top5 = 0.5875
[2017-11-20 22:58:45]:
-Iter 40600, Training Loss= 0.116093, Accuracy Top1 = 0.9875, Top5 = 1.0000
-Iter 40600, Validation Loss= 4.274996, Accuracy Top1 = 0.3500, Top5 = 0.5500
[2017-11-20 23:00:07]:
-Iter 40700, Training Loss= 0.161640, Accuracy Top1 = 0.9750, Top5 = 1.0000
-Iter 40700, Validation Loss= 2.956339, Accuracy Top1 = 0.4250, Top5 = 0.7250
[2017-11-20 23:01:28]:
-Iter 40800, Training Loss= 0.168804, Accuracy Top1 = 0.9500, Top5 = 1.0000
-Iter 40800, Validation Loss= 4.079876, Accuracy Top1 = 0.3000, Top5 = 0.6875
[2017-11-20 23:02:50]:
-Iter 40900, Training Loss= 0.286350, Accuracy Top1 = 0.8875, Top5 = 0.9875
-Iter 40900, Validation Loss= 3.211683, Accuracy Top1 = 0.4625, Top5 = 0.7375
[2017-11-20 23:04:11]:
-Iter 41000, Training Loss= 0.195375, Accuracy Top1 = 0.9500, Top5 = 1.0000
-Iter 41000, Validation Loss= 3.592103, Accuracy Top1 = 0.4000, Top5 = 0.7125
[2017-11-20 23:05:32]:
-Iter 41100, Training Loss= 0.118756, Accuracy Top1 = 0.9625, Top5 = 1.0000
-Iter 41100, Validation Loss= 4.159057, Accuracy Top1 = 0.3750, Top5 = 0.6750
